{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "from itertools import combinations_with_replacement\n",
    "from numpy.linalg import qr, norm\n",
    "import open3d as o3d\n",
    "import datetime\n",
    "from utils import Logger, mkdir_p, progress_bar, save_model, save_args, cal_loss\n",
    "\n",
    "import sklearn.metrics as metrics\n",
    "from data import ModelNet40\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "import sklearn.metrics as metrics\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import combinations_with_replacement\n",
    "\n",
    "def generate_monomials_sequences_batch(X, degree):\n",
    "    \"\"\"\n",
    "    Generate monomials up to a given degree for d-dimensional points.\n",
    "\n",
    "    Parameters:\n",
    "        X (ndarray): An array of shape (B, N, d) representing the point cloud.\n",
    "        degree (int): The maximum degree of the monomials.\n",
    "\n",
    "    Returns:\n",
    "        ndarray: Monomial matrix of shape (B, N, M).\n",
    "    \"\"\"\n",
    "    B, N, d = X.shape\n",
    "    device = X.device\n",
    "    exponents = []\n",
    "    # Generate all multi-indices with total degree up to 'degree'\n",
    "    for total_degree in range(degree + 1):\n",
    "        for exps in combinations_with_replacement(range(d), total_degree):\n",
    "            exp = torch.zeros(d, dtype=int, device=device)\n",
    "            for var in exps:\n",
    "                exp[var] += 1\n",
    "            exponents.append(exp)\n",
    "    M = len(exponents)\n",
    "    # print(f'Number of monomials: {M}') # Number of polynomials: n1 + n2 + ... + n_d = degree; degree + d choose d; d number of dividers for an array in space R^d.\n",
    "    monomials = torch.ones(B, N, M, device=device)\n",
    "    for i, exp in enumerate(exponents):\n",
    "        monomials[:, :, i] = torch.prod(X ** exp, axis=2) # x1^exp1 * x2^exp2 * ... * xd^expd. e.g. x1^2 * x2^3 * x3^1 \\in R^3\n",
    "    return monomials.sum(dim=1) / N # (B, N, M) -> (B, M)\n",
    "\n",
    "def generate_chebyshev_polynomials_sequence_batch(X, degree):\n",
    "    \"\"\"\n",
    "    Generate Chebyshev polynomials up to a given degree for d-dimensional points.\n",
    "\n",
    "    Parameters:\n",
    "        X (ndarray): An array of shape (B, N, d) representing the d-dimensional point cloud.\n",
    "        degree (int): The maximum degree of the polynomials.\n",
    "\n",
    "    Returns:\n",
    "        ndarray: Chebyshev polynomial matrix of shape (B, N, M).\n",
    "    \"\"\"\n",
    "    B, N, d = X.shape\n",
    "    device = X.device\n",
    "    exponents = []\n",
    "    # Generate all multi-indices with total degree up to 'degree'\n",
    "    for total_degree in range(degree + 1):\n",
    "        for exps in combinations_with_replacement(range(d), total_degree):\n",
    "            exp = torch.zeros(d, dtype=int, device=device)\n",
    "            for var in exps:\n",
    "                exp[var] += 1\n",
    "            exponents.append(exp)\n",
    "    M = len(exponents)\n",
    "    # print(f'Number of Chebyshev polynomials: {M}') # Number of polynomials: n1 + n2 + ... + n_d = degree; degree + d choose d; d number of dividers for an array in space R^d.\n",
    "    cheby_polynomials = torch.ones(B, N, M, device=device)\n",
    "    for i, exp in enumerate(exponents):\n",
    "        cheby_polynomials[:, :, i] = torch.prod(torch.cos(exp * torch.acos(X)), axis=2)\n",
    "    return cheby_polynomials.sum(dim=1) / N # (B, N, M) -> (B, M)\n",
    "\n",
    "def poly_seq_batch(X, degree, poly_type='monomials'):\n",
    "    if poly_type == 'monomials':\n",
    "        return generate_monomials_sequences_batch(X, degree)\n",
    "    elif poly_type == 'chebyshev':\n",
    "        return generate_chebyshev_polynomials_sequence_batch(X, degree)\n",
    "    else:\n",
    "        raise ValueError('Invalid polynomial type')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use ModelNet40 as our dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_points = 2048\n",
    "batch_size = 32\n",
    "\n",
    "train_loader = DataLoader(ModelNet40(partition='train', \n",
    "                                        num_points=num_points,\n",
    "                                        aug=True), \n",
    "                            num_workers=8,\n",
    "                            batch_size=batch_size, \n",
    "                            shuffle=True, \n",
    "                            drop_last=True)\n",
    "test_loader = DataLoader(ModelNet40(partition='test', \n",
    "                                        num_points=num_points,\n",
    "                                        aug=False), \n",
    "                            num_workers=8,\n",
    "                            batch_size=batch_size // 2, \n",
    "                            shuffle=False, \n",
    "                            drop_last=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A simple Linear classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 40])\n"
     ]
    }
   ],
   "source": [
    "class MLPClaasifier(nn.Module):\n",
    "    def __init__(self, dim_in, layer_dims, dim_out):\n",
    "        super(MLPClaasifier, self).__init__()\n",
    "        self.convs = nn.ModuleList()\n",
    "        self.convs.append(nn.Sequential(\n",
    "            nn.Linear(dim_in, layer_dims[0]),\n",
    "            nn.BatchNorm1d(layer_dims[0]),\n",
    "            nn.ReLU(),\n",
    "        ))\n",
    "        for i in range(1, len(layer_dims)):\n",
    "            self.convs.append(nn.Sequential(\n",
    "                nn.Linear(layer_dims[i-1], layer_dims[i]),\n",
    "                nn.BatchNorm1d(layer_dims[i]),\n",
    "                nn.ReLU(),\n",
    "            ))\n",
    "        self.convs.append(nn.Linear(layer_dims[-1], dim_out))\n",
    "\n",
    "    def forward(self, x):\n",
    "        for i, conv in enumerate(self.convs[:-1]):\n",
    "            x = conv(x)\n",
    "        x = self.convs[-1](x)\n",
    "        return x\n",
    "    \n",
    "x = torch.randn(32, 100) # 32 samples, 100 features\n",
    "model = MLPClaasifier(100, [128, 64], 40)\n",
    "y = model(x)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 40])\n"
     ]
    }
   ],
   "source": [
    "class MomentNet(nn.Module):\n",
    "    def __init__(self, dim_in, layer_dims, dim_out, degree, poly_type='monomials'):\n",
    "        super(MomentNet, self).__init__()\n",
    "        self.poly_type = poly_type\n",
    "        self.degree = degree\n",
    "        self.num_poly = math.comb(degree + dim_in, dim_in)\n",
    "        self.mlp = MLPClaasifier(self.num_poly, layer_dims, dim_out)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = poly_seq_batch(x, self.degree, self.poly_type)\n",
    "        x = self.mlp(x)\n",
    "        return x\n",
    "    \n",
    "x = torch.randn(32, 2048, 3) # 32 samples, 2048 points, 3 features\n",
    "model = MomentNet(3, [128, 64], 40, 2, 'monomials')\n",
    "y = model(x)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(net, trainloader, optimizer, criterion, epoch, num_epochs, device):\n",
    "    net.train()\n",
    "    train_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    train_pred = []\n",
    "    train_true = []\n",
    "    time_cost = datetime.datetime.now()\n",
    "    pbar = tqdm(enumerate(trainloader), total=len(trainloader))\n",
    "    for batch_idx, (data, label) in pbar:\n",
    "        data, label = data.to(device), label.to(device).squeeze()\n",
    "        optimizer.zero_grad()\n",
    "        logits = net(data)\n",
    "        loss = criterion(logits, label)\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(net.parameters(), 1)\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()\n",
    "        preds = logits.max(dim=1)[1]\n",
    "\n",
    "        train_true.append(label.cpu().numpy())\n",
    "        train_pred.append(preds.detach().cpu().numpy())\n",
    "\n",
    "        total += label.size(0)\n",
    "        correct += preds.eq(label).sum().item()\n",
    "\n",
    "        pbar.set_description(f'({epoch:3d}/{num_epochs:3d}) Loss: {train_loss / (batch_idx + 1):.3f} | Acc: {100. * correct / total:.3f}% ({correct}/{total})')\n",
    "        # progress_bar(batch_idx, len(trainloader), 'Loss: %.3f | Acc: %.3f%% (%d/%d)'\n",
    "        #              % (train_loss / (batch_idx + 1), 100. * correct / total, correct, total))\n",
    "\n",
    "    time_cost = int((datetime.datetime.now() - time_cost).total_seconds())\n",
    "    train_true = np.concatenate(train_true)\n",
    "    train_pred = np.concatenate(train_pred)\n",
    "    return {\n",
    "        \"loss\": float(\"%.3f\" % (train_loss / (batch_idx + 1))),\n",
    "        \"acc\": float(\"%.3f\" % (100. * metrics.accuracy_score(train_true, train_pred))),\n",
    "        \"acc_avg\": float(\"%.3f\" % (100. * metrics.balanced_accuracy_score(train_true, train_pred))),\n",
    "        \"time\": time_cost\n",
    "    }\n",
    "\n",
    "\n",
    "def validate(net, testloader, criterion, epoch, num_epochs, device):\n",
    "    net.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    test_true = []\n",
    "    test_pred = []\n",
    "    time_cost = datetime.datetime.now()\n",
    "    with torch.no_grad():\n",
    "        pbar = tqdm(enumerate(testloader), total=len(testloader))\n",
    "        for batch_idx, (data, label) in pbar:\n",
    "            data, label = data.to(device), label.to(device).squeeze()\n",
    "            logits = net(data)\n",
    "            loss = criterion(logits, label)\n",
    "            test_loss += loss.item()\n",
    "            preds = logits.max(dim=1)[1]\n",
    "            test_true.append(label.cpu().numpy())\n",
    "            test_pred.append(preds.detach().cpu().numpy())\n",
    "            total += label.size(0)\n",
    "            correct += preds.eq(label).sum().item()\n",
    "            pbar.set_description(f'({epoch:3d}/{num_epochs:3d}) Loss: {test_loss / (batch_idx + 1):.3f} | Acc: {100. * correct / total:.3f}% ({correct}/{total})')\n",
    "            # progress_bar(batch_idx, len(testloader), 'Loss: %.3f | Acc: %.3f%% (%d/%d)'\n",
    "            #              % (test_loss / (batch_idx + 1), 100. * correct / total, correct, total))\n",
    "\n",
    "    time_cost = int((datetime.datetime.now() - time_cost).total_seconds())\n",
    "    test_true = np.concatenate(test_true)\n",
    "    test_pred = np.concatenate(test_pred)\n",
    "    return {\n",
    "        \"loss\": float(\"%.3f\" % (test_loss / (batch_idx + 1))),\n",
    "        \"acc\": float(\"%.3f\" % (100. * metrics.accuracy_score(test_true, test_pred))),\n",
    "        \"acc_avg\": float(\"%.3f\" % (100. * metrics.balanced_accuracy_score(test_true, test_pred))),\n",
    "        \"time\": time_cost\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "969\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(  0/100) Loss: 1.307 | Acc: 64.190% (6306/9824): 100%|██████████| 307/307 [00:34<00:00,  8.94it/s]\n",
      "(  0/100) Loss: 0.930 | Acc: 72.407% (1787/2468): 100%|██████████| 155/155 [00:16<00:00,  9.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss:1.307 acc_avg:49.719% acc:64.19% time:34s\n",
      "Testing loss:0.93 acc_avg:61.624% acc:72.407% time:17s [best test acc: 72.407%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "(  1/100) Loss: 0.855 | Acc: 74.522% (7321/9824): 100%|██████████| 307/307 [00:33<00:00,  9.28it/s]\n",
      "(  1/100) Loss: 0.809 | Acc: 77.107% (1903/2468): 100%|██████████| 155/155 [00:16<00:00,  9.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss:0.855 acc_avg:63.976% acc:74.522% time:33s\n",
      "Testing loss:0.809 acc_avg:69.459% acc:77.107% time:16s [best test acc: 77.107%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "(  2/100) Loss: 0.743 | Acc: 77.952% (7658/9824): 100%|██████████| 307/307 [00:33<00:00,  9.27it/s]\n",
      "(  2/100) Loss: 0.802 | Acc: 76.742% (1894/2468): 100%|██████████| 155/155 [00:16<00:00,  9.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss:0.743 acc_avg:68.761% acc:77.952% time:33s\n",
      "Testing loss:0.802 acc_avg:68.909% acc:76.742% time:16s [best test acc: 77.107%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "(  3/100) Loss: 0.644 | Acc: 80.222% (7881/9824): 100%|██████████| 307/307 [00:33<00:00,  9.25it/s]\n",
      "(  3/100) Loss: 0.666 | Acc: 81.321% (2007/2468): 100%|██████████| 155/155 [00:16<00:00,  9.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss:0.644 acc_avg:71.885% acc:80.222% time:33s\n",
      "Testing loss:0.666 acc_avg:73.79% acc:81.321% time:16s [best test acc: 81.321%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "(  4/100) Loss: 0.586 | Acc: 81.952% (8051/9824): 100%|██████████| 307/307 [00:32<00:00,  9.34it/s]\n",
      "(  4/100) Loss: 0.652 | Acc: 81.199% (2004/2468): 100%|██████████| 155/155 [00:15<00:00,  9.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss:0.586 acc_avg:74.105% acc:81.952% time:33s\n",
      "Testing loss:0.652 acc_avg:73.178% acc:81.199% time:16s [best test acc: 81.321%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "(  5/100) Loss: 0.548 | Acc: 83.072% (8161/9824): 100%|██████████| 307/307 [00:32<00:00,  9.46it/s]\n",
      "(  5/100) Loss: 0.709 | Acc: 80.105% (1977/2468): 100%|██████████| 155/155 [00:15<00:00,  9.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss:0.548 acc_avg:75.668% acc:83.072% time:32s\n",
      "Testing loss:0.709 acc_avg:74.079% acc:80.105% time:16s [best test acc: 81.321%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "(  6/100) Loss: 0.479 | Acc: 84.914% (8342/9824): 100%|██████████| 307/307 [00:33<00:00,  9.27it/s]\n",
      "(  6/100) Loss: 0.630 | Acc: 82.253% (2030/2468): 100%|██████████| 155/155 [00:16<00:00,  9.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss:0.479 acc_avg:78.424% acc:84.914% time:33s\n",
      "Testing loss:0.63 acc_avg:76.385% acc:82.253% time:16s [best test acc: 82.253%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "(  7/100) Loss: 0.458 | Acc: 85.403% (8390/9824): 100%|██████████| 307/307 [00:33<00:00,  9.28it/s]\n",
      "(  7/100) Loss: 0.650 | Acc: 81.361% (2008/2468): 100%|██████████| 155/155 [00:16<00:00,  9.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss:0.458 acc_avg:79.244% acc:85.403% time:33s\n",
      "Testing loss:0.65 acc_avg:73.119% acc:81.361% time:16s [best test acc: 82.253%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "(  8/100) Loss: 0.436 | Acc: 85.943% (8443/9824): 100%|██████████| 307/307 [00:33<00:00,  9.27it/s]\n",
      "(  8/100) Loss: 0.672 | Acc: 81.442% (2010/2468): 100%|██████████| 155/155 [00:15<00:00,  9.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss:0.436 acc_avg:79.571% acc:85.943% time:33s\n",
      "Testing loss:0.672 acc_avg:74.566% acc:81.442% time:16s [best test acc: 82.253%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "(  9/100) Loss: 0.401 | Acc: 86.798% (8527/9824): 100%|██████████| 307/307 [00:32<00:00,  9.59it/s]\n",
      "(  9/100) Loss: 0.659 | Acc: 79.619% (1965/2468): 100%|██████████| 155/155 [00:15<00:00,  9.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss:0.401 acc_avg:80.848% acc:86.798% time:32s\n",
      "Testing loss:0.659 acc_avg:74.831% acc:79.619% time:16s [best test acc: 82.253%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "( 10/100) Loss: 0.371 | Acc: 87.561% (8602/9824): 100%|██████████| 307/307 [00:32<00:00,  9.38it/s]\n",
      "( 10/100) Loss: 0.614 | Acc: 82.496% (2036/2468): 100%|██████████| 155/155 [00:16<00:00,  9.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss:0.371 acc_avg:81.999% acc:87.561% time:33s\n",
      "Testing loss:0.614 acc_avg:76.112% acc:82.496% time:16s [best test acc: 82.496%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "( 11/100) Loss: 0.359 | Acc: 88.202% (8665/9824): 100%|██████████| 307/307 [00:33<00:00,  9.21it/s]\n",
      "( 11/100) Loss: 0.623 | Acc: 82.050% (2025/2468): 100%|██████████| 155/155 [00:16<00:00,  9.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss:0.359 acc_avg:83.05% acc:88.202% time:33s\n",
      "Testing loss:0.623 acc_avg:76.645% acc:82.05% time:16s [best test acc: 82.496%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "( 12/100) Loss: 0.339 | Acc: 88.986% (8742/9824): 100%|██████████| 307/307 [00:33<00:00,  9.26it/s]\n",
      "( 12/100) Loss: 0.639 | Acc: 82.455% (2035/2468): 100%|██████████| 155/155 [00:16<00:00,  9.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss:0.339 acc_avg:84.106% acc:88.986% time:33s\n",
      "Testing loss:0.639 acc_avg:77.533% acc:82.455% time:16s [best test acc: 82.496%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "( 13/100) Loss: 0.326 | Acc: 89.078% (8751/9824): 100%|██████████| 307/307 [00:32<00:00,  9.55it/s]\n",
      "( 13/100) Loss: 0.644 | Acc: 83.509% (2061/2468): 100%|██████████| 155/155 [00:15<00:00,  9.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss:0.326 acc_avg:84.407% acc:89.078% time:32s\n",
      "Testing loss:0.644 acc_avg:77.728% acc:83.509% time:16s [best test acc: 83.509%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "( 14/100) Loss: 0.305 | Acc: 89.475% (8790/9824): 100%|██████████| 307/307 [00:32<00:00,  9.54it/s]\n",
      "( 14/100) Loss: 0.641 | Acc: 83.144% (2052/2468): 100%|██████████| 155/155 [00:16<00:00,  9.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss:0.305 acc_avg:84.747% acc:89.475% time:32s\n",
      "Testing loss:0.641 acc_avg:77.202% acc:83.144% time:16s [best test acc: 83.509%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "( 15/100) Loss: 0.313 | Acc: 89.536% (8796/9824): 100%|██████████| 307/307 [00:34<00:00,  8.92it/s]\n",
      "( 15/100) Loss: 0.580 | Acc: 84.846% (2094/2468): 100%|██████████| 155/155 [00:16<00:00,  9.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss:0.313 acc_avg:84.853% acc:89.536% time:34s\n",
      "Testing loss:0.58 acc_avg:78.14% acc:84.846% time:17s [best test acc: 84.846%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "( 16/100) Loss: 0.280 | Acc: 90.381% (8879/9824): 100%|██████████| 307/307 [00:33<00:00,  9.06it/s]\n",
      "( 16/100) Loss: 0.678 | Acc: 83.063% (2050/2468): 100%|██████████| 155/155 [00:16<00:00,  9.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss:0.28 acc_avg:86.423% acc:90.381% time:34s\n",
      "Testing loss:0.678 acc_avg:77.784% acc:83.063% time:16s [best test acc: 84.846%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "( 17/100) Loss: 0.280 | Acc: 90.421% (8883/9824): 100%|██████████| 307/307 [00:33<00:00,  9.06it/s]\n",
      "( 17/100) Loss: 0.653 | Acc: 84.198% (2078/2468): 100%|██████████| 155/155 [00:16<00:00,  9.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss:0.28 acc_avg:86.325% acc:90.421% time:34s\n",
      "Testing loss:0.653 acc_avg:78.991% acc:84.198% time:16s [best test acc: 84.846%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "( 18/100) Loss: 0.256 | Acc: 91.144% (8954/9824): 100%|██████████| 307/307 [00:33<00:00,  9.14it/s]\n",
      "( 18/100) Loss: 0.678 | Acc: 82.820% (2044/2468): 100%|██████████| 155/155 [00:16<00:00,  9.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss:0.256 acc_avg:87.301% acc:91.144% time:34s\n",
      "Testing loss:0.678 acc_avg:77.488% acc:82.82% time:17s [best test acc: 84.846%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "( 19/100) Loss: 0.241 | Acc: 91.714% (9010/9824): 100%|██████████| 307/307 [00:33<00:00,  9.05it/s]\n",
      "( 19/100) Loss: 0.640 | Acc: 84.117% (2076/2468): 100%|██████████| 155/155 [00:16<00:00,  9.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss:0.241 acc_avg:88.165% acc:91.714% time:34s\n",
      "Testing loss:0.64 acc_avg:78.92% acc:84.117% time:16s [best test acc: 84.846%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "( 20/100) Loss: 0.229 | Acc: 91.938% (9032/9824): 100%|██████████| 307/307 [00:33<00:00,  9.13it/s]\n",
      "( 20/100) Loss: 0.702 | Acc: 83.428% (2059/2468): 100%|██████████| 155/155 [00:16<00:00,  9.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss:0.229 acc_avg:88.409% acc:91.938% time:34s\n",
      "Testing loss:0.702 acc_avg:77.567% acc:83.428% time:17s [best test acc: 84.846%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "( 21/100) Loss: 0.235 | Acc: 91.877% (9026/9824): 100%|██████████| 307/307 [00:33<00:00,  9.17it/s]\n",
      "( 21/100) Loss: 0.698 | Acc: 83.712% (2066/2468): 100%|██████████| 155/155 [00:16<00:00,  9.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss:0.235 acc_avg:88.201% acc:91.877% time:33s\n",
      "Testing loss:0.698 acc_avg:78.703% acc:83.712% time:17s [best test acc: 84.846%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "( 22/100) Loss: 0.220 | Acc: 92.142% (9052/9824): 100%|██████████| 307/307 [00:33<00:00,  9.19it/s]\n",
      "( 22/100) Loss: 0.715 | Acc: 82.699% (2041/2468): 100%|██████████| 155/155 [00:16<00:00,  9.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss:0.22 acc_avg:88.753% acc:92.142% time:33s\n",
      "Testing loss:0.715 acc_avg:77.454% acc:82.699% time:16s [best test acc: 84.846%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "( 23/100) Loss: 0.211 | Acc: 92.386% (9076/9824): 100%|██████████| 307/307 [00:33<00:00,  9.12it/s]\n",
      "( 23/100) Loss: 0.756 | Acc: 82.699% (2041/2468): 100%|██████████| 155/155 [00:16<00:00,  9.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss:0.211 acc_avg:89.14% acc:92.386% time:34s\n",
      "Testing loss:0.756 acc_avg:78.831% acc:82.699% time:17s [best test acc: 84.846%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "( 24/100) Loss: 0.197 | Acc: 92.783% (9115/9824): 100%|██████████| 307/307 [00:33<00:00,  9.25it/s]\n",
      "( 24/100) Loss: 0.723 | Acc: 83.752% (2067/2468): 100%|██████████| 155/155 [00:16<00:00,  9.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss:0.197 acc_avg:89.465% acc:92.783% time:33s\n",
      "Testing loss:0.723 acc_avg:78.366% acc:83.752% time:16s [best test acc: 84.846%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "( 25/100) Loss: 0.198 | Acc: 93.353% (9171/9824): 100%|██████████| 307/307 [00:33<00:00,  9.13it/s]\n",
      "( 25/100) Loss: 0.745 | Acc: 83.630% (2064/2468): 100%|██████████| 155/155 [00:16<00:00,  9.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss:0.198 acc_avg:90.416% acc:93.353% time:34s\n",
      "Testing loss:0.745 acc_avg:77.987% acc:83.63% time:16s [best test acc: 84.846%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "( 26/100) Loss: 0.179 | Acc: 93.343% (9170/9824): 100%|██████████| 307/307 [00:34<00:00,  9.03it/s]\n",
      "( 26/100) Loss: 0.723 | Acc: 84.562% (2087/2468): 100%|██████████| 155/155 [00:16<00:00,  9.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss:0.179 acc_avg:90.571% acc:93.343% time:34s\n",
      "Testing loss:0.723 acc_avg:79.702% acc:84.562% time:16s [best test acc: 84.846%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "( 27/100) Loss: 0.176 | Acc: 93.689% (9204/9824): 100%|██████████| 307/307 [00:33<00:00,  9.13it/s]\n",
      "( 27/100) Loss: 0.727 | Acc: 83.833% (2069/2468): 100%|██████████| 155/155 [00:16<00:00,  9.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss:0.176 acc_avg:91.135% acc:93.689% time:34s\n",
      "Testing loss:0.727 acc_avg:78.104% acc:83.833% time:17s [best test acc: 84.846%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "( 28/100) Loss: 0.170 | Acc: 93.893% (9224/9824): 100%|██████████| 307/307 [00:33<00:00,  9.11it/s]\n",
      "( 28/100) Loss: 0.770 | Acc: 84.117% (2076/2468): 100%|██████████| 155/155 [00:16<00:00,  9.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss:0.17 acc_avg:91.226% acc:93.893% time:34s\n",
      "Testing loss:0.77 acc_avg:79.22% acc:84.117% time:16s [best test acc: 84.846%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "( 29/100) Loss: 0.163 | Acc: 94.025% (9237/9824): 100%|██████████| 307/307 [00:33<00:00,  9.14it/s]\n",
      "( 29/100) Loss: 0.832 | Acc: 83.914% (2071/2468): 100%|██████████| 155/155 [00:16<00:00,  9.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss:0.163 acc_avg:91.558% acc:94.025% time:34s\n",
      "Testing loss:0.832 acc_avg:78.599% acc:83.914% time:16s [best test acc: 84.846%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "( 30/100) Loss: 0.165 | Acc: 94.127% (9247/9824): 100%|██████████| 307/307 [00:33<00:00,  9.08it/s]\n",
      "( 30/100) Loss: 0.741 | Acc: 85.049% (2099/2468): 100%|██████████| 155/155 [00:16<00:00,  9.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss:0.165 acc_avg:91.45% acc:94.127% time:34s\n",
      "Testing loss:0.741 acc_avg:78.607% acc:85.049% time:17s [best test acc: 85.049%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "( 31/100) Loss: 0.154 | Acc: 94.524% (9286/9824): 100%|██████████| 307/307 [00:33<00:00,  9.08it/s]\n",
      "( 31/100) Loss: 0.777 | Acc: 83.671% (2065/2468): 100%|██████████| 155/155 [00:16<00:00,  9.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss:0.154 acc_avg:92.158% acc:94.524% time:34s\n",
      "Testing loss:0.777 acc_avg:78.658% acc:83.671% time:16s [best test acc: 85.049%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "( 32/100) Loss: 0.146 | Acc: 94.676% (9301/9824): 100%|██████████| 307/307 [00:33<00:00,  9.16it/s]\n",
      "( 32/100) Loss: 0.804 | Acc: 83.590% (2063/2468): 100%|██████████| 155/155 [00:16<00:00,  9.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss:0.146 acc_avg:92.358% acc:94.676% time:33s\n",
      "Testing loss:0.804 acc_avg:77.837% acc:83.59% time:16s [best test acc: 85.049%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "( 33/100) Loss: 0.141 | Acc: 94.717% (9305/9824): 100%|██████████| 307/307 [00:33<00:00,  9.11it/s]\n",
      "( 33/100) Loss: 0.801 | Acc: 84.927% (2096/2468): 100%|██████████| 155/155 [00:16<00:00,  9.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss:0.141 acc_avg:92.416% acc:94.717% time:34s\n",
      "Testing loss:0.801 acc_avg:79.553% acc:84.927% time:16s [best test acc: 85.049%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "( 34/100) Loss: 0.136 | Acc: 94.951% (9328/9824): 100%|██████████| 307/307 [00:33<00:00,  9.14it/s]\n",
      "( 34/100) Loss: 0.808 | Acc: 84.360% (2082/2468): 100%|██████████| 155/155 [00:16<00:00,  9.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss:0.136 acc_avg:92.755% acc:94.951% time:34s\n",
      "Testing loss:0.808 acc_avg:79.466% acc:84.36% time:17s [best test acc: 85.049%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "( 35/100) Loss: 0.134 | Acc: 95.226% (9355/9824): 100%|██████████| 307/307 [00:33<00:00,  9.12it/s]\n",
      "( 35/100) Loss: 0.788 | Acc: 83.874% (2070/2468): 100%|██████████| 155/155 [00:16<00:00,  9.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss:0.134 acc_avg:93.207% acc:95.226% time:34s\n",
      "Testing loss:0.788 acc_avg:79.416% acc:83.874% time:17s [best test acc: 85.049%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "( 36/100) Loss: 0.123 | Acc: 95.531% (9385/9824): 100%|██████████| 307/307 [00:33<00:00,  9.07it/s]\n",
      "( 36/100) Loss: 0.783 | Acc: 84.400% (2083/2468): 100%|██████████| 155/155 [00:16<00:00,  9.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss:0.123 acc_avg:93.606% acc:95.531% time:34s\n",
      "Testing loss:0.783 acc_avg:79.237% acc:84.4% time:17s [best test acc: 85.049%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "( 37/100) Loss: 0.116 | Acc: 95.664% (9398/9824): 100%|██████████| 307/307 [00:33<00:00,  9.14it/s]\n",
      "( 37/100) Loss: 0.838 | Acc: 83.995% (2073/2468): 100%|██████████| 155/155 [00:16<00:00,  9.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss:0.116 acc_avg:93.747% acc:95.664% time:34s\n",
      "Testing loss:0.838 acc_avg:79.438% acc:83.995% time:17s [best test acc: 85.049%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "( 38/100) Loss: 0.112 | Acc: 95.796% (9411/9824): 100%|██████████| 307/307 [00:34<00:00,  9.01it/s]\n",
      "( 38/100) Loss: 0.819 | Acc: 84.968% (2097/2468): 100%|██████████| 155/155 [00:16<00:00,  9.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss:0.112 acc_avg:93.977% acc:95.796% time:34s\n",
      "Testing loss:0.819 acc_avg:79.75% acc:84.968% time:17s [best test acc: 85.049%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "( 39/100) Loss: 0.105 | Acc: 95.959% (9427/9824): 100%|██████████| 307/307 [00:33<00:00,  9.14it/s]\n",
      "( 39/100) Loss: 0.839 | Acc: 84.441% (2084/2468): 100%|██████████| 155/155 [00:16<00:00,  9.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss:0.105 acc_avg:94.052% acc:95.959% time:34s\n",
      "Testing loss:0.839 acc_avg:79.795% acc:84.441% time:17s [best test acc: 85.049%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "( 40/100) Loss: 0.103 | Acc: 96.142% (9445/9824): 100%|██████████| 307/307 [00:33<00:00,  9.10it/s]\n",
      "( 40/100) Loss: 0.870 | Acc: 84.036% (2074/2468): 100%|██████████| 155/155 [00:16<00:00,  9.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss:0.103 acc_avg:94.448% acc:96.142% time:34s\n",
      "Testing loss:0.87 acc_avg:79.433% acc:84.036% time:17s [best test acc: 85.049%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "( 41/100) Loss: 0.104 | Acc: 96.122% (9443/9824): 100%|██████████| 307/307 [00:32<00:00,  9.34it/s]\n",
      "( 41/100) Loss: 0.935 | Acc: 84.238% (2079/2468): 100%|██████████| 155/155 [00:16<00:00,  9.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss:0.104 acc_avg:94.31% acc:96.122% time:33s\n",
      "Testing loss:0.935 acc_avg:78.89% acc:84.238% time:16s [best test acc: 85.049%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "( 42/100) Loss: 0.101 | Acc: 96.295% (9460/9824): 100%|██████████| 307/307 [00:33<00:00,  9.07it/s]\n",
      "( 42/100) Loss: 0.867 | Acc: 84.238% (2079/2468): 100%|██████████| 155/155 [00:16<00:00,  9.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss:0.101 acc_avg:94.857% acc:96.295% time:34s\n",
      "Testing loss:0.867 acc_avg:79.283% acc:84.238% time:17s [best test acc: 85.049%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "( 43/100) Loss: 0.097 | Acc: 96.315% (9462/9824): 100%|██████████| 307/307 [00:33<00:00,  9.12it/s]\n",
      "( 43/100) Loss: 0.866 | Acc: 84.198% (2078/2468): 100%|██████████| 155/155 [00:16<00:00,  9.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss:0.097 acc_avg:94.858% acc:96.315% time:34s\n",
      "Testing loss:0.866 acc_avg:79.707% acc:84.198% time:17s [best test acc: 85.049%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "( 44/100) Loss: 0.087 | Acc: 96.702% (9500/9824): 100%|██████████| 307/307 [00:33<00:00,  9.13it/s]\n",
      "( 44/100) Loss: 0.853 | Acc: 85.049% (2099/2468): 100%|██████████| 155/155 [00:16<00:00,  9.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss:0.087 acc_avg:95.327% acc:96.702% time:34s\n",
      "Testing loss:0.853 acc_avg:79.77% acc:85.049% time:17s [best test acc: 85.049%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "( 45/100) Loss: 0.086 | Acc: 96.855% (9515/9824): 100%|██████████| 307/307 [00:33<00:00,  9.11it/s]\n",
      "( 45/100) Loss: 0.925 | Acc: 84.481% (2085/2468): 100%|██████████| 155/155 [00:16<00:00,  9.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss:0.086 acc_avg:95.576% acc:96.855% time:34s\n",
      "Testing loss:0.925 acc_avg:79.59% acc:84.481% time:17s [best test acc: 85.049%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "( 46/100) Loss: 0.086 | Acc: 96.946% (9524/9824): 100%|██████████| 307/307 [00:33<00:00,  9.08it/s]\n",
      "( 46/100) Loss: 0.903 | Acc: 84.157% (2077/2468): 100%|██████████| 155/155 [00:16<00:00,  9.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss:0.086 acc_avg:95.585% acc:96.946% time:34s\n",
      "Testing loss:0.903 acc_avg:79.545% acc:84.157% time:16s [best test acc: 85.049%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "( 47/100) Loss: 0.076 | Acc: 97.007% (9530/9824): 100%|██████████| 307/307 [00:33<00:00,  9.14it/s]\n",
      "( 47/100) Loss: 0.875 | Acc: 85.494% (2110/2468): 100%|██████████| 155/155 [00:16<00:00,  9.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss:0.076 acc_avg:95.548% acc:97.007% time:34s\n",
      "Testing loss:0.875 acc_avg:80.39% acc:85.494% time:17s [best test acc: 85.494%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "( 48/100) Loss: 0.079 | Acc: 97.099% (9539/9824): 100%|██████████| 307/307 [00:33<00:00,  9.13it/s]\n",
      "( 48/100) Loss: 0.918 | Acc: 82.982% (2048/2468): 100%|██████████| 155/155 [00:16<00:00,  9.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss:0.079 acc_avg:95.938% acc:97.099% time:34s\n",
      "Testing loss:0.918 acc_avg:77.791% acc:82.982% time:17s [best test acc: 85.494%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "( 49/100) Loss: 0.077 | Acc: 97.058% (9535/9824): 100%|██████████| 307/307 [00:33<00:00,  9.09it/s]\n",
      "( 49/100) Loss: 0.980 | Acc: 83.104% (2051/2468): 100%|██████████| 155/155 [00:16<00:00,  9.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss:0.077 acc_avg:95.845% acc:97.058% time:34s\n",
      "Testing loss:0.98 acc_avg:78.859% acc:83.104% time:16s [best test acc: 85.494%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "( 50/100) Loss: 0.070 | Acc: 97.537% (9582/9824): 100%|██████████| 307/307 [00:34<00:00,  9.01it/s]\n",
      "( 50/100) Loss: 0.914 | Acc: 84.441% (2084/2468): 100%|██████████| 155/155 [00:16<00:00,  9.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss:0.07 acc_avg:96.406% acc:97.537% time:34s\n",
      "Testing loss:0.914 acc_avg:79.92% acc:84.441% time:17s [best test acc: 85.494%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "( 51/100) Loss: 0.064 | Acc: 97.496% (9578/9824): 100%|██████████| 307/307 [00:33<00:00,  9.16it/s]\n",
      "( 51/100) Loss: 0.951 | Acc: 84.036% (2074/2468): 100%|██████████| 155/155 [00:16<00:00,  9.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss:0.064 acc_avg:96.242% acc:97.496% time:33s\n",
      "Testing loss:0.951 acc_avg:79.198% acc:84.036% time:16s [best test acc: 85.494%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "( 52/100) Loss: 0.059 | Acc: 97.832% (9611/9824): 100%|██████████| 307/307 [00:33<00:00,  9.09it/s]\n",
      "( 52/100) Loss: 0.981 | Acc: 84.238% (2079/2468): 100%|██████████| 155/155 [00:16<00:00,  9.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss:0.059 acc_avg:96.852% acc:97.832% time:34s\n",
      "Testing loss:0.981 acc_avg:79.496% acc:84.238% time:17s [best test acc: 85.494%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "( 53/100) Loss: 0.061 | Acc: 97.628% (9591/9824): 100%|██████████| 307/307 [00:34<00:00,  9.03it/s]\n",
      "( 53/100) Loss: 0.959 | Acc: 83.874% (2070/2468): 100%|██████████| 155/155 [00:16<00:00,  9.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss:0.061 acc_avg:96.558% acc:97.628% time:34s\n",
      "Testing loss:0.959 acc_avg:79.391% acc:83.874% time:17s [best test acc: 85.494%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "( 54/100) Loss: 0.063 | Acc: 97.618% (9590/9824): 100%|██████████| 307/307 [00:33<00:00,  9.09it/s]\n",
      "( 54/100) Loss: 0.957 | Acc: 84.724% (2091/2468): 100%|██████████| 155/155 [00:16<00:00,  9.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss:0.063 acc_avg:96.649% acc:97.618% time:34s\n",
      "Testing loss:0.957 acc_avg:80.17% acc:84.724% time:16s [best test acc: 85.494%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "( 55/100) Loss: 0.054 | Acc: 97.852% (9613/9824): 100%|██████████| 307/307 [00:33<00:00,  9.11it/s]\n",
      "( 55/100) Loss: 0.968 | Acc: 83.955% (2072/2468): 100%|██████████| 155/155 [00:16<00:00,  9.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss:0.054 acc_avg:96.716% acc:97.852% time:34s\n",
      "Testing loss:0.968 acc_avg:78.98% acc:83.955% time:16s [best test acc: 85.494%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "( 56/100) Loss: 0.053 | Acc: 98.025% (9630/9824): 100%|██████████| 307/307 [00:33<00:00,  9.08it/s]\n",
      "( 56/100) Loss: 0.961 | Acc: 84.643% (2089/2468): 100%|██████████| 155/155 [00:16<00:00,  9.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss:0.053 acc_avg:97.167% acc:98.025% time:34s\n",
      "Testing loss:0.961 acc_avg:79.728% acc:84.643% time:16s [best test acc: 85.494%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "( 57/100) Loss: 0.049 | Acc: 98.035% (9631/9824): 100%|██████████| 307/307 [00:33<00:00,  9.08it/s]\n",
      "( 57/100) Loss: 0.961 | Acc: 83.590% (2063/2468): 100%|██████████| 155/155 [00:16<00:00,  9.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss:0.049 acc_avg:97.171% acc:98.035% time:34s\n",
      "Testing loss:0.961 acc_avg:79.066% acc:83.59% time:17s [best test acc: 85.494%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "( 58/100) Loss: 0.045 | Acc: 98.259% (9653/9824): 100%|██████████| 307/307 [00:33<00:00,  9.14it/s]\n",
      "( 58/100) Loss: 0.983 | Acc: 84.522% (2086/2468): 100%|██████████| 155/155 [00:16<00:00,  9.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss:0.045 acc_avg:97.582% acc:98.259% time:34s\n",
      "Testing loss:0.983 acc_avg:79.358% acc:84.522% time:17s [best test acc: 85.494%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "( 59/100) Loss: 0.047 | Acc: 98.219% (9649/9824): 100%|██████████| 307/307 [00:33<00:00,  9.12it/s]\n",
      "( 59/100) Loss: 0.992 | Acc: 84.117% (2076/2468): 100%|██████████| 155/155 [00:16<00:00,  9.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss:0.047 acc_avg:97.297% acc:98.219% time:34s\n",
      "Testing loss:0.992 acc_avg:79.953% acc:84.117% time:16s [best test acc: 85.494%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "( 60/100) Loss: 0.046 | Acc: 98.117% (9639/9824): 100%|██████████| 307/307 [00:33<00:00,  9.08it/s]\n",
      "( 60/100) Loss: 1.010 | Acc: 84.481% (2085/2468): 100%|██████████| 155/155 [00:16<00:00,  9.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss:0.046 acc_avg:97.353% acc:98.117% time:34s\n",
      "Testing loss:1.01 acc_avg:79.471% acc:84.481% time:16s [best test acc: 85.494%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "( 61/100) Loss: 0.045 | Acc: 98.320% (9659/9824): 100%|██████████| 307/307 [00:33<00:00,  9.09it/s]\n",
      "( 61/100) Loss: 1.020 | Acc: 83.671% (2065/2468): 100%|██████████| 155/155 [00:16<00:00,  9.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss:0.045 acc_avg:97.626% acc:98.32% time:34s\n",
      "Testing loss:1.02 acc_avg:78.559% acc:83.671% time:17s [best test acc: 85.494%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "( 62/100) Loss: 0.042 | Acc: 98.259% (9653/9824): 100%|██████████| 307/307 [00:34<00:00,  8.93it/s]\n",
      "( 62/100) Loss: 1.046 | Acc: 84.238% (2079/2468): 100%|██████████| 155/155 [00:16<00:00,  9.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss:0.042 acc_avg:97.473% acc:98.259% time:34s\n",
      "Testing loss:1.046 acc_avg:80.001% acc:84.238% time:17s [best test acc: 85.494%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "( 63/100) Loss: 0.039 | Acc: 98.463% (9673/9824): 100%|██████████| 307/307 [00:33<00:00,  9.07it/s]\n",
      "( 63/100) Loss: 1.050 | Acc: 83.793% (2068/2468): 100%|██████████| 155/155 [00:16<00:00,  9.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss:0.039 acc_avg:97.786% acc:98.463% time:34s\n",
      "Testing loss:1.05 acc_avg:78.729% acc:83.793% time:16s [best test acc: 85.494%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "( 64/100) Loss: 0.037 | Acc: 98.636% (9690/9824): 100%|██████████| 307/307 [00:33<00:00,  9.16it/s]\n",
      "( 64/100) Loss: 1.054 | Acc: 83.874% (2070/2468): 100%|██████████| 155/155 [00:16<00:00,  9.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss:0.037 acc_avg:97.948% acc:98.636% time:33s\n",
      "Testing loss:1.054 acc_avg:78.68% acc:83.874% time:16s [best test acc: 85.494%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "( 65/100) Loss: 0.038 | Acc: 98.514% (9678/9824): 100%|██████████| 307/307 [00:33<00:00,  9.07it/s]\n",
      "( 65/100) Loss: 1.013 | Acc: 84.036% (2074/2468): 100%|██████████| 155/155 [00:16<00:00,  9.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss:0.038 acc_avg:97.827% acc:98.514% time:34s\n",
      "Testing loss:1.013 acc_avg:79.108% acc:84.036% time:17s [best test acc: 85.494%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "( 66/100) Loss: 0.037 | Acc: 98.544% (9681/9824): 100%|██████████| 307/307 [00:33<00:00,  9.09it/s]\n",
      "( 66/100) Loss: 1.016 | Acc: 84.117% (2076/2468): 100%|██████████| 155/155 [00:16<00:00,  9.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss:0.037 acc_avg:97.859% acc:98.544% time:34s\n",
      "Testing loss:1.016 acc_avg:79.662% acc:84.117% time:17s [best test acc: 85.494%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "( 67/100) Loss: 0.034 | Acc: 98.697% (9696/9824): 100%|██████████| 307/307 [00:33<00:00,  9.06it/s]\n",
      "( 67/100) Loss: 1.032 | Acc: 84.522% (2086/2468): 100%|██████████| 155/155 [00:16<00:00,  9.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss:0.034 acc_avg:98.094% acc:98.697% time:34s\n",
      "Testing loss:1.032 acc_avg:79.492% acc:84.522% time:16s [best test acc: 85.494%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "( 68/100) Loss: 0.031 | Acc: 98.840% (9710/9824): 100%|██████████| 307/307 [00:32<00:00,  9.35it/s]\n",
      "( 68/100) Loss: 1.025 | Acc: 84.157% (2077/2468): 100%|██████████| 155/155 [00:16<00:00,  9.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss:0.031 acc_avg:98.42% acc:98.84% time:33s\n",
      "Testing loss:1.025 acc_avg:79.496% acc:84.157% time:16s [best test acc: 85.494%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "( 69/100) Loss: 0.031 | Acc: 98.829% (9709/9824): 100%|██████████| 307/307 [00:33<00:00,  9.13it/s]\n",
      "( 69/100) Loss: 1.041 | Acc: 84.400% (2083/2468): 100%|██████████| 155/155 [00:16<00:00,  9.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss:0.031 acc_avg:98.32% acc:98.829% time:34s\n",
      "Testing loss:1.041 acc_avg:79.829% acc:84.4% time:16s [best test acc: 85.494%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "( 70/100) Loss: 0.030 | Acc: 98.819% (9708/9824): 100%|██████████| 307/307 [00:33<00:00,  9.10it/s]\n",
      "( 70/100) Loss: 1.040 | Acc: 84.319% (2081/2468): 100%|██████████| 155/155 [00:16<00:00,  9.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss:0.03 acc_avg:98.309% acc:98.819% time:34s\n",
      "Testing loss:1.04 acc_avg:79.946% acc:84.319% time:16s [best test acc: 85.494%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "( 71/100) Loss: 0.027 | Acc: 98.890% (9715/9824): 100%|██████████| 307/307 [00:34<00:00,  8.85it/s]\n",
      "( 71/100) Loss: 1.040 | Acc: 84.724% (2091/2468): 100%|██████████| 155/155 [00:16<00:00,  9.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss:0.027 acc_avg:98.303% acc:98.89% time:35s\n",
      "Testing loss:1.04 acc_avg:80.124% acc:84.724% time:17s [best test acc: 85.494%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "( 72/100) Loss: 0.026 | Acc: 99.053% (9731/9824): 100%|██████████| 307/307 [00:34<00:00,  8.97it/s]\n",
      "( 72/100) Loss: 1.081 | Acc: 84.360% (2082/2468): 100%|██████████| 155/155 [00:16<00:00,  9.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss:0.026 acc_avg:98.633% acc:99.053% time:34s\n",
      "Testing loss:1.081 acc_avg:79.492% acc:84.36% time:16s [best test acc: 85.494%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "( 73/100) Loss: 0.028 | Acc: 98.819% (9708/9824): 100%|██████████| 307/307 [00:33<00:00,  9.07it/s]\n",
      "( 73/100) Loss: 1.085 | Acc: 84.360% (2082/2468): 100%|██████████| 155/155 [00:16<00:00,  9.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss:0.028 acc_avg:98.218% acc:98.819% time:34s\n",
      "Testing loss:1.085 acc_avg:80.12% acc:84.36% time:17s [best test acc: 85.494%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "( 74/100) Loss: 0.025 | Acc: 99.033% (9729/9824): 100%|██████████| 307/307 [00:33<00:00,  9.06it/s]\n",
      "( 74/100) Loss: 1.070 | Acc: 84.360% (2082/2468): 100%|██████████| 155/155 [00:16<00:00,  9.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss:0.025 acc_avg:98.57% acc:99.033% time:34s\n",
      "Testing loss:1.07 acc_avg:80.328% acc:84.36% time:16s [best test acc: 85.494%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "( 75/100) Loss: 0.027 | Acc: 98.931% (9719/9824): 100%|██████████| 307/307 [00:33<00:00,  9.06it/s]\n",
      "( 75/100) Loss: 1.095 | Acc: 84.643% (2089/2468): 100%|██████████| 155/155 [00:16<00:00,  9.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss:0.027 acc_avg:98.539% acc:98.931% time:34s\n",
      "Testing loss:1.095 acc_avg:80.091% acc:84.643% time:17s [best test acc: 85.494%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "( 76/100) Loss: 0.024 | Acc: 99.114% (9737/9824): 100%|██████████| 307/307 [00:33<00:00,  9.12it/s]\n",
      "( 76/100) Loss: 1.077 | Acc: 84.806% (2093/2468): 100%|██████████| 155/155 [00:16<00:00,  9.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss:0.024 acc_avg:98.763% acc:99.114% time:34s\n",
      "Testing loss:1.077 acc_avg:80.245% acc:84.806% time:16s [best test acc: 85.494%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "( 77/100) Loss: 0.024 | Acc: 99.053% (9731/9824): 100%|██████████| 307/307 [00:34<00:00,  8.90it/s]\n",
      "( 77/100) Loss: 1.096 | Acc: 84.562% (2087/2468): 100%|██████████| 155/155 [00:16<00:00,  9.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss:0.024 acc_avg:98.682% acc:99.053% time:34s\n",
      "Testing loss:1.096 acc_avg:80.512% acc:84.562% time:17s [best test acc: 85.494%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "( 78/100) Loss: 0.026 | Acc: 98.911% (9717/9824): 100%|██████████| 307/307 [00:33<00:00,  9.13it/s]\n",
      "( 78/100) Loss: 1.130 | Acc: 84.076% (2075/2468): 100%|██████████| 155/155 [00:16<00:00,  9.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss:0.026 acc_avg:98.392% acc:98.911% time:34s\n",
      "Testing loss:1.13 acc_avg:79.103% acc:84.076% time:16s [best test acc: 85.494%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "( 79/100) Loss: 0.023 | Acc: 99.074% (9733/9824): 100%|██████████| 307/307 [00:33<00:00,  9.06it/s]\n",
      "( 79/100) Loss: 1.099 | Acc: 84.360% (2082/2468): 100%|██████████| 155/155 [00:16<00:00,  9.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss:0.023 acc_avg:98.602% acc:99.074% time:34s\n",
      "Testing loss:1.099 acc_avg:79.962% acc:84.36% time:17s [best test acc: 85.494%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "( 80/100) Loss: 0.024 | Acc: 99.033% (9729/9824): 100%|██████████| 307/307 [00:33<00:00,  9.12it/s]\n",
      "( 80/100) Loss: 1.084 | Acc: 84.238% (2079/2468): 100%|██████████| 155/155 [00:16<00:00,  9.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss:0.024 acc_avg:98.665% acc:99.033% time:34s\n",
      "Testing loss:1.084 acc_avg:79.779% acc:84.238% time:17s [best test acc: 85.494%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "( 81/100) Loss: 0.022 | Acc: 99.043% (9730/9824): 100%|██████████| 307/307 [00:33<00:00,  9.15it/s]\n",
      "( 81/100) Loss: 1.089 | Acc: 83.955% (2072/2468): 100%|██████████| 155/155 [00:16<00:00,  9.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss:0.022 acc_avg:98.58% acc:99.043% time:34s\n",
      "Testing loss:1.089 acc_avg:79.613% acc:83.955% time:16s [best test acc: 85.494%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "( 82/100) Loss: 0.022 | Acc: 99.186% (9744/9824): 100%|██████████| 307/307 [00:33<00:00,  9.06it/s]\n",
      "( 82/100) Loss: 1.099 | Acc: 84.684% (2090/2468): 100%|██████████| 155/155 [00:16<00:00,  9.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss:0.022 acc_avg:98.898% acc:99.186% time:34s\n",
      "Testing loss:1.099 acc_avg:80.387% acc:84.684% time:16s [best test acc: 85.494%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "( 83/100) Loss: 0.022 | Acc: 99.114% (9737/9824): 100%|██████████| 307/307 [00:33<00:00,  9.10it/s]\n",
      "( 83/100) Loss: 1.118 | Acc: 84.522% (2086/2468): 100%|██████████| 155/155 [00:16<00:00,  9.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss:0.022 acc_avg:98.754% acc:99.114% time:34s\n",
      "Testing loss:1.118 acc_avg:80.275% acc:84.522% time:17s [best test acc: 85.494%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "( 84/100) Loss: 0.021 | Acc: 99.114% (9737/9824): 100%|██████████| 307/307 [00:33<00:00,  9.13it/s]\n",
      "( 84/100) Loss: 1.101 | Acc: 84.036% (2074/2468): 100%|██████████| 155/155 [00:16<00:00,  9.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss:0.021 acc_avg:98.693% acc:99.114% time:34s\n",
      "Testing loss:1.101 acc_avg:79.696% acc:84.036% time:17s [best test acc: 85.494%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "( 85/100) Loss: 0.021 | Acc: 99.114% (9737/9824): 100%|██████████| 307/307 [00:33<00:00,  9.12it/s]\n",
      "( 85/100) Loss: 1.142 | Acc: 84.279% (2080/2468): 100%|██████████| 155/155 [00:16<00:00,  9.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss:0.021 acc_avg:98.712% acc:99.114% time:34s\n",
      "Testing loss:1.142 acc_avg:79.938% acc:84.279% time:16s [best test acc: 85.494%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "( 86/100) Loss: 0.020 | Acc: 99.257% (9751/9824): 100%|██████████| 307/307 [00:33<00:00,  9.21it/s]\n",
      "( 86/100) Loss: 1.124 | Acc: 84.319% (2081/2468): 100%|██████████| 155/155 [00:16<00:00,  9.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss:0.02 acc_avg:98.932% acc:99.257% time:33s\n",
      "Testing loss:1.124 acc_avg:80.087% acc:84.319% time:17s [best test acc: 85.494%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "( 87/100) Loss: 0.021 | Acc: 99.165% (9742/9824): 100%|██████████| 307/307 [00:33<00:00,  9.12it/s]\n",
      "( 87/100) Loss: 1.103 | Acc: 84.319% (2081/2468): 100%|██████████| 155/155 [00:16<00:00,  9.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss:0.021 acc_avg:98.795% acc:99.165% time:34s\n",
      "Testing loss:1.103 acc_avg:79.875% acc:84.319% time:16s [best test acc: 85.494%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "( 88/100) Loss: 0.019 | Acc: 99.206% (9746/9824): 100%|██████████| 307/307 [00:33<00:00,  9.11it/s]\n",
      "( 88/100) Loss: 1.127 | Acc: 84.157% (2077/2468): 100%|██████████| 155/155 [00:16<00:00,  9.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss:0.019 acc_avg:98.85% acc:99.206% time:34s\n",
      "Testing loss:1.127 acc_avg:79.595% acc:84.157% time:17s [best test acc: 85.494%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "( 89/100) Loss: 0.018 | Acc: 99.338% (9759/9824): 100%|██████████| 307/307 [00:33<00:00,  9.11it/s]\n",
      "( 89/100) Loss: 1.134 | Acc: 84.238% (2079/2468): 100%|██████████| 155/155 [00:16<00:00,  9.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss:0.018 acc_avg:99.151% acc:99.338% time:34s\n",
      "Testing loss:1.134 acc_avg:80.129% acc:84.238% time:17s [best test acc: 85.494%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "( 90/100) Loss: 0.019 | Acc: 99.216% (9747/9824): 100%|██████████| 307/307 [00:33<00:00,  9.13it/s]\n",
      "( 90/100) Loss: 1.115 | Acc: 84.360% (2082/2468): 100%|██████████| 155/155 [00:16<00:00,  9.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss:0.019 acc_avg:98.882% acc:99.216% time:34s\n",
      "Testing loss:1.115 acc_avg:79.828% acc:84.36% time:17s [best test acc: 85.494%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "( 91/100) Loss: 0.018 | Acc: 99.298% (9755/9824): 100%|██████████| 307/307 [00:33<00:00,  9.12it/s]\n",
      "( 91/100) Loss: 1.114 | Acc: 84.238% (2079/2468): 100%|██████████| 155/155 [00:16<00:00,  9.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss:0.018 acc_avg:98.978% acc:99.298% time:34s\n",
      "Testing loss:1.114 acc_avg:80.049% acc:84.238% time:17s [best test acc: 85.494%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "( 92/100) Loss: 0.019 | Acc: 99.226% (9748/9824): 100%|██████████| 307/307 [00:33<00:00,  9.04it/s]\n",
      "( 92/100) Loss: 1.143 | Acc: 84.279% (2080/2468): 100%|██████████| 155/155 [00:16<00:00,  9.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss:0.019 acc_avg:98.906% acc:99.226% time:34s\n",
      "Testing loss:1.143 acc_avg:79.97% acc:84.279% time:17s [best test acc: 85.494%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "( 93/100) Loss: 0.017 | Acc: 99.328% (9758/9824): 100%|██████████| 307/307 [00:33<00:00,  9.14it/s]\n",
      "( 93/100) Loss: 1.157 | Acc: 83.793% (2068/2468): 100%|██████████| 155/155 [00:16<00:00,  9.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss:0.017 acc_avg:98.969% acc:99.328% time:34s\n",
      "Testing loss:1.157 acc_avg:79.178% acc:83.793% time:17s [best test acc: 85.494%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "( 94/100) Loss: 0.019 | Acc: 99.226% (9748/9824): 100%|██████████| 307/307 [00:33<00:00,  9.04it/s]\n",
      "( 94/100) Loss: 1.122 | Acc: 84.036% (2074/2468): 100%|██████████| 155/155 [00:16<00:00,  9.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss:0.019 acc_avg:98.948% acc:99.226% time:34s\n",
      "Testing loss:1.122 acc_avg:79.704% acc:84.036% time:16s [best test acc: 85.494%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "( 95/100) Loss: 0.017 | Acc: 99.349% (9760/9824): 100%|██████████| 307/307 [00:32<00:00,  9.33it/s]\n",
      "( 95/100) Loss: 1.148 | Acc: 84.360% (2082/2468): 100%|██████████| 155/155 [00:16<00:00,  9.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss:0.017 acc_avg:99.024% acc:99.349% time:33s\n",
      "Testing loss:1.148 acc_avg:80.116% acc:84.36% time:16s [best test acc: 85.494%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "( 96/100) Loss: 0.018 | Acc: 99.359% (9761/9824): 100%|██████████| 307/307 [00:33<00:00,  9.15it/s]\n",
      "( 96/100) Loss: 1.158 | Acc: 84.117% (2076/2468): 100%|██████████| 155/155 [00:16<00:00,  9.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss:0.018 acc_avg:99.129% acc:99.359% time:34s\n",
      "Testing loss:1.158 acc_avg:79.87% acc:84.117% time:17s [best test acc: 85.494%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "( 97/100) Loss: 0.019 | Acc: 99.298% (9755/9824): 100%|██████████| 307/307 [00:33<00:00,  9.09it/s]\n",
      "( 97/100) Loss: 1.143 | Acc: 84.319% (2081/2468): 100%|██████████| 155/155 [00:16<00:00,  9.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss:0.019 acc_avg:99.089% acc:99.298% time:34s\n",
      "Testing loss:1.143 acc_avg:80.387% acc:84.319% time:17s [best test acc: 85.494%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "( 98/100) Loss: 0.017 | Acc: 99.257% (9751/9824): 100%|██████████| 307/307 [00:33<00:00,  9.08it/s]\n",
      "( 98/100) Loss: 1.131 | Acc: 84.198% (2078/2468): 100%|██████████| 155/155 [00:16<00:00,  9.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss:0.017 acc_avg:98.933% acc:99.257% time:34s\n",
      "Testing loss:1.131 acc_avg:79.916% acc:84.198% time:17s [best test acc: 85.494%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "( 99/100) Loss: 0.016 | Acc: 99.369% (9762/9824): 100%|██████████| 307/307 [00:33<00:00,  9.09it/s]\n",
      "( 99/100) Loss: 1.136 | Acc: 84.036% (2074/2468): 100%|██████████| 155/155 [00:16<00:00,  9.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss:0.016 acc_avg:99.154% acc:99.369% time:34s\n",
      "Testing loss:1.136 acc_avg:79.383% acc:84.036% time:16s [best test acc: 85.494%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Training (Taken from PointMLP-PyTorch)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "num_epochs = 100 # Number of epochs\n",
    "eval_every = 10 # Evaluate every 'eval_every' epochs\n",
    "max_lr = 0.1 # Maximum learning rate\n",
    "min_lr = 0.005 # Minimum learning rate\n",
    "\n",
    "best_test_acc = 0.  # best test accuracy\n",
    "best_train_acc = 0.\n",
    "best_test_acc_avg = 0.\n",
    "best_train_acc_avg = 0.\n",
    "best_test_loss = float(\"inf\")\n",
    "best_train_loss = float(\"inf\")\n",
    "start_epoch = 0  # start from epoch 0 or last checkpoint epoch\n",
    "\n",
    "# Model\n",
    "net = MomentNet(3, [512, 256, 128], 40, degree = 16, poly_type = 'chebyshev').to(device)\n",
    "print(net.num_poly)\n",
    "\n",
    "# Optimizer\n",
    "optimizer = torch.optim.SGD(net.parameters(), lr=max_lr, momentum=0.9, weight_decay=0)\n",
    "scheduler = CosineAnnealingLR(optimizer, num_epochs, eta_min=min_lr, last_epoch=start_epoch - 1)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "for epoch in range(start_epoch, num_epochs):\n",
    "    train_out = train(net, train_loader, optimizer, criterion, epoch, num_epochs, device)  # {\"loss\", \"acc\", \"acc_avg\", \"time\"}\n",
    "    test_out = validate(net, test_loader, criterion, epoch, num_epochs, device)\n",
    "    scheduler.step()\n",
    "    if test_out[\"acc\"] > best_test_acc:\n",
    "        best_test_acc = test_out[\"acc\"]\n",
    "        is_best = True\n",
    "    else:\n",
    "        is_best = False\n",
    "\n",
    "    best_test_acc = test_out[\"acc\"] if (test_out[\"acc\"] > best_test_acc) else best_test_acc\n",
    "    best_train_acc = train_out[\"acc\"] if (train_out[\"acc\"] > best_train_acc) else best_train_acc\n",
    "    best_test_acc_avg = test_out[\"acc_avg\"] if (test_out[\"acc_avg\"] > best_test_acc_avg) else best_test_acc_avg\n",
    "    best_train_acc_avg = train_out[\"acc_avg\"] if (train_out[\"acc_avg\"] > best_train_acc_avg) else best_train_acc_avg\n",
    "    best_test_loss = test_out[\"loss\"] if (test_out[\"loss\"] < best_test_loss) else best_test_loss\n",
    "    best_train_loss = train_out[\"loss\"] if (train_out[\"loss\"] < best_train_loss) else best_train_loss\n",
    "    \n",
    "    print(\n",
    "        f\"Training loss:{train_out['loss']} acc_avg:{train_out['acc_avg']}% acc:{train_out['acc']}% time:{train_out['time']}s\")\n",
    "    print(\n",
    "        f\"Testing loss:{test_out['loss']} acc_avg:{test_out['acc_avg']}% \"\n",
    "        f\"acc:{test_out['acc']}% time:{test_out['time']}s [best test acc: {best_test_acc}%]\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch3d",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
