{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "from itertools import combinations_with_replacement\n",
    "from numpy.linalg import qr, norm\n",
    "import open3d as o3d\n",
    "import datetime\n",
    "from utils import Logger, mkdir_p, progress_bar, save_model, save_args, cal_loss\n",
    "\n",
    "import sklearn.metrics as metrics\n",
    "from data import ModelNet40\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "import sklearn.metrics as metrics\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import combinations_with_replacement\n",
    "\n",
    "def generate_monomials_sequences_batch(X, degree):\n",
    "    \"\"\"\n",
    "    Generate monomials up to a given degree for d-dimensional points.\n",
    "\n",
    "    Parameters:\n",
    "        X (ndarray): An array of shape (B, N, d) representing the point cloud.\n",
    "        degree (int): The maximum degree of the monomials.\n",
    "\n",
    "    Returns:\n",
    "        ndarray: Monomial matrix of shape (B, N, M).\n",
    "    \"\"\"\n",
    "    B, N, d = X.shape\n",
    "    device = X.device\n",
    "    exponents = []\n",
    "    # Generate all multi-indices with total degree up to 'degree'\n",
    "    for total_degree in range(degree + 1):\n",
    "        for exps in combinations_with_replacement(range(d), total_degree):\n",
    "            exp = torch.zeros(d, dtype=int, device=device)\n",
    "            for var in exps:\n",
    "                exp[var] += 1\n",
    "            exponents.append(exp)\n",
    "    M = len(exponents)\n",
    "    # print(f'Number of monomials: {M}') # Number of polynomials: n1 + n2 + ... + n_d = degree; degree + d choose d; d number of dividers for an array in space R^d.\n",
    "    monomials = torch.ones(B, N, M, device=device)\n",
    "    for i, exp in enumerate(exponents):\n",
    "        monomials[:, :, i] = torch.prod(X ** exp, axis=2) # x1^exp1 * x2^exp2 * ... * xd^expd. e.g. x1^2 * x2^3 * x3^1 \\in R^3\n",
    "    return monomials.sum(dim=1) / N # (B, N, M) -> (B, M)\n",
    "\n",
    "def generate_chebyshev_polynomials_sequence_batch(X, degree):\n",
    "    \"\"\"\n",
    "    Generate Chebyshev polynomials up to a given degree for d-dimensional points.\n",
    "\n",
    "    Parameters:\n",
    "        X (ndarray): An array of shape (B, N, d) representing the d-dimensional point cloud.\n",
    "        degree (int): The maximum degree of the polynomials.\n",
    "\n",
    "    Returns:\n",
    "        ndarray: Chebyshev polynomial matrix of shape (B, N, M).\n",
    "    \"\"\"\n",
    "    B, N, d = X.shape\n",
    "    device = X.device\n",
    "    exponents = []\n",
    "    # Generate all multi-indices with total degree up to 'degree'\n",
    "    for total_degree in range(degree + 1):\n",
    "        for exps in combinations_with_replacement(range(d), total_degree):\n",
    "            exp = torch.zeros(d, dtype=int, device=device)\n",
    "            for var in exps:\n",
    "                exp[var] += 1\n",
    "            exponents.append(exp)\n",
    "    M = len(exponents)\n",
    "    # print(f'Number of Chebyshev polynomials: {M}') # Number of polynomials: n1 + n2 + ... + n_d = degree; degree + d choose d; d number of dividers for an array in space R^d.\n",
    "    cheby_polynomials = torch.ones(B, N, M, device=device)\n",
    "    for i, exp in enumerate(exponents):\n",
    "        cheby_polynomials[:, :, i] = torch.prod(torch.cos(exp * torch.acos(X)), axis=2)\n",
    "    return cheby_polynomials.sum(dim=1) / N # (B, N, M) -> (B, M)\n",
    "\n",
    "def poly_seq_batch(X, degree, poly_type='monomials'):\n",
    "    if poly_type == 'monomials':\n",
    "        return generate_monomials_sequences_batch(X, degree)\n",
    "    elif poly_type == 'chebyshev':\n",
    "        return generate_chebyshev_polynomials_sequence_batch(X, degree)\n",
    "    else:\n",
    "        raise ValueError('Invalid polynomial type')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use ModelNet40 as our dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_points = 2048\n",
    "batch_size = 32\n",
    "\n",
    "train_loader = DataLoader(ModelNet40(partition='train', \n",
    "                                        num_points=num_points,\n",
    "                                        aug=False), \n",
    "                            num_workers=8,\n",
    "                            batch_size=batch_size, \n",
    "                            shuffle=True, \n",
    "                            drop_last=True)\n",
    "test_loader = DataLoader(ModelNet40(partition='test', \n",
    "                                        num_points=num_points,\n",
    "                                        aug=False), \n",
    "                            num_workers=8,\n",
    "                            batch_size=batch_size // 2, \n",
    "                            shuffle=False, \n",
    "                            drop_last=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A simple Linear classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 40])\n"
     ]
    }
   ],
   "source": [
    "class MLPClaasifier(nn.Module):\n",
    "    def __init__(self, dim_in, layer_dims, dim_out):\n",
    "        super(MLPClaasifier, self).__init__()\n",
    "        self.convs = nn.ModuleList()\n",
    "        self.convs.append(nn.Sequential(\n",
    "            nn.Linear(dim_in, layer_dims[0]),\n",
    "            nn.BatchNorm1d(layer_dims[0]),\n",
    "            nn.ReLU(),\n",
    "        ))\n",
    "        for i in range(1, len(layer_dims)):\n",
    "            self.convs.append(nn.Sequential(\n",
    "                nn.Linear(layer_dims[i-1], layer_dims[i]),\n",
    "                nn.BatchNorm1d(layer_dims[i]),\n",
    "                nn.ReLU(),\n",
    "            ))\n",
    "        self.convs.append(nn.Linear(layer_dims[-1], dim_out))\n",
    "\n",
    "    def forward(self, x):\n",
    "        for i, conv in enumerate(self.convs[:-1]):\n",
    "            x = conv(x)\n",
    "        x = self.convs[-1](x)\n",
    "        return x\n",
    "    \n",
    "x = torch.randn(32, 100) # 32 samples, 100 features\n",
    "model = MLPClaasifier(100, [128, 64], 40)\n",
    "y = model(x)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 40])\n"
     ]
    }
   ],
   "source": [
    "class MomentNet(nn.Module):\n",
    "    def __init__(self, dim_in, layer_dims, dim_out, degree, poly_type='monomials'):\n",
    "        super(MomentNet, self).__init__()\n",
    "        self.poly_type = poly_type\n",
    "        self.degree = degree\n",
    "        self.num_poly = math.comb(degree + dim_in, dim_in)\n",
    "        self.mlp = MLPClaasifier(self.num_poly, layer_dims, dim_out)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = poly_seq_batch(x, self.degree, self.poly_type)\n",
    "        x = self.mlp(x)\n",
    "        return x\n",
    "    \n",
    "x = torch.randn(32, 2048, 3) # 32 samples, 2048 points, 3 features\n",
    "model = MomentNet(3, [128, 64], 40, 2, 'monomials')\n",
    "y = model(x)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(net, trainloader, optimizer, criterion, epoch, num_epochs, device):\n",
    "    net.train()\n",
    "    train_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    train_pred = []\n",
    "    train_true = []\n",
    "    time_cost = datetime.datetime.now()\n",
    "    pbar = tqdm(enumerate(trainloader), total=len(trainloader))\n",
    "    for batch_idx, (data, label) in pbar:\n",
    "        data, label = data.to(device), label.to(device).squeeze()\n",
    "        optimizer.zero_grad()\n",
    "        logits = net(data)\n",
    "        loss = criterion(logits, label)\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(net.parameters(), 1)\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()\n",
    "        preds = logits.max(dim=1)[1]\n",
    "\n",
    "        train_true.append(label.cpu().numpy())\n",
    "        train_pred.append(preds.detach().cpu().numpy())\n",
    "\n",
    "        total += label.size(0)\n",
    "        correct += preds.eq(label).sum().item()\n",
    "\n",
    "        pbar.set_description(f'({epoch:3d}/{num_epochs:3d}) Loss: {train_loss / (batch_idx + 1):.3f} | Acc: {100. * correct / total:.3f}% ({correct}/{total})')\n",
    "        # progress_bar(batch_idx, len(trainloader), 'Loss: %.3f | Acc: %.3f%% (%d/%d)'\n",
    "        #              % (train_loss / (batch_idx + 1), 100. * correct / total, correct, total))\n",
    "\n",
    "    time_cost = int((datetime.datetime.now() - time_cost).total_seconds())\n",
    "    train_true = np.concatenate(train_true)\n",
    "    train_pred = np.concatenate(train_pred)\n",
    "    return {\n",
    "        \"loss\": float(\"%.3f\" % (train_loss / (batch_idx + 1))),\n",
    "        \"acc\": float(\"%.3f\" % (100. * metrics.accuracy_score(train_true, train_pred))),\n",
    "        \"acc_avg\": float(\"%.3f\" % (100. * metrics.balanced_accuracy_score(train_true, train_pred))),\n",
    "        \"time\": time_cost\n",
    "    }\n",
    "\n",
    "\n",
    "def validate(net, testloader, criterion, epoch, num_epochs, device):\n",
    "    net.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    test_true = []\n",
    "    test_pred = []\n",
    "    time_cost = datetime.datetime.now()\n",
    "    with torch.no_grad():\n",
    "        pbar = tqdm(enumerate(testloader), total=len(testloader))\n",
    "        for batch_idx, (data, label) in pbar:\n",
    "            data, label = data.to(device), label.to(device).squeeze()\n",
    "            logits = net(data)\n",
    "            loss = criterion(logits, label)\n",
    "            test_loss += loss.item()\n",
    "            preds = logits.max(dim=1)[1]\n",
    "            test_true.append(label.cpu().numpy())\n",
    "            test_pred.append(preds.detach().cpu().numpy())\n",
    "            total += label.size(0)\n",
    "            correct += preds.eq(label).sum().item()\n",
    "            pbar.set_description(f'({epoch:3d}/{num_epochs:3d}) Loss: {test_loss / (batch_idx + 1):.3f} | Acc: {100. * correct / total:.3f}% ({correct}/{total})')\n",
    "            # progress_bar(batch_idx, len(testloader), 'Loss: %.3f | Acc: %.3f%% (%d/%d)'\n",
    "            #              % (test_loss / (batch_idx + 1), 100. * correct / total, correct, total))\n",
    "\n",
    "    time_cost = int((datetime.datetime.now() - time_cost).total_seconds())\n",
    "    test_true = np.concatenate(test_true)\n",
    "    test_pred = np.concatenate(test_pred)\n",
    "    return {\n",
    "        \"loss\": float(\"%.3f\" % (test_loss / (batch_idx + 1))),\n",
    "        \"acc\": float(\"%.3f\" % (100. * metrics.accuracy_score(test_true, test_pred))),\n",
    "        \"acc_avg\": float(\"%.3f\" % (100. * metrics.balanced_accuracy_score(test_true, test_pred))),\n",
    "        \"time\": time_cost\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "455\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(  0/100) Loss: 1.323 | Acc: 62.663% (6156/9824): 100%|██████████| 307/307 [00:17<00:00, 17.88it/s]\n",
      "(  0/100) Loss: 0.953 | Acc: 72.326% (0.723257698541329): 100%|██████████| 155/155 [00:07<00:00, 21.11it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss:1.323 acc_avg:47.933% acc:62.663% time:17s\n",
      "Testing loss:0.953 acc_avg:62.177% acc:72.326% time:7s [best test acc: 72.326%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "(  1/100) Loss: 0.904 | Acc: 73.544% (7225/9824): 100%|██████████| 307/307 [00:14<00:00, 20.81it/s]\n",
      "(  1/100) Loss: 0.880 | Acc: 73.703% (0.7370340356564019): 100%|██████████| 155/155 [00:07<00:00, 21.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss:0.904 acc_avg:62.874% acc:73.544% time:15s\n",
      "Testing loss:0.88 acc_avg:64.467% acc:73.703% time:7s [best test acc: 73.703%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "(  2/100) Loss: 0.769 | Acc: 76.893% (7554/9824): 100%|██████████| 307/307 [00:14<00:00, 20.77it/s]\n",
      "(  2/100) Loss: 0.787 | Acc: 76.459% (0.7645867098865479): 100%|██████████| 155/155 [00:07<00:00, 21.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss:0.769 acc_avg:67.905% acc:76.893% time:15s\n",
      "Testing loss:0.787 acc_avg:66.265% acc:76.459% time:7s [best test acc: 76.459%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "(  3/100) Loss: 0.701 | Acc: 78.654% (7727/9824): 100%|██████████| 307/307 [00:14<00:00, 20.55it/s]\n",
      "(  3/100) Loss: 0.751 | Acc: 78.241% (0.7824149108589952): 100%|██████████| 155/155 [00:07<00:00, 21.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss:0.701 acc_avg:70.046% acc:78.654% time:15s\n",
      "Testing loss:0.751 acc_avg:70.484% acc:78.241% time:7s [best test acc: 78.241%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "(  4/100) Loss: 0.627 | Acc: 80.527% (7911/9824): 100%|██████████| 307/307 [00:14<00:00, 20.47it/s]\n",
      "(  4/100) Loss: 0.714 | Acc: 79.214% (0.7921393841166937): 100%|██████████| 155/155 [00:07<00:00, 21.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss:0.627 acc_avg:72.617% acc:80.527% time:15s\n",
      "Testing loss:0.714 acc_avg:71.189% acc:79.214% time:7s [best test acc: 79.214%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "(  5/100) Loss: 0.596 | Acc: 81.484% (8005/9824): 100%|██████████| 307/307 [00:14<00:00, 20.66it/s]\n",
      "(  5/100) Loss: 0.652 | Acc: 80.956% (0.8095623987034035): 100%|██████████| 155/155 [00:07<00:00, 21.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss:0.596 acc_avg:74.075% acc:81.484% time:15s\n",
      "Testing loss:0.652 acc_avg:72.756% acc:80.956% time:7s [best test acc: 80.956%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "(  6/100) Loss: 0.562 | Acc: 82.563% (8111/9824): 100%|██████████| 307/307 [00:14<00:00, 20.55it/s]\n",
      "(  6/100) Loss: 0.673 | Acc: 79.092% (0.7909238249594813): 100%|██████████| 155/155 [00:07<00:00, 21.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss:0.562 acc_avg:75.108% acc:82.563% time:15s\n",
      "Testing loss:0.673 acc_avg:71.883% acc:79.092% time:7s [best test acc: 80.956%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "(  7/100) Loss: 0.521 | Acc: 83.418% (8195/9824): 100%|██████████| 307/307 [00:14<00:00, 20.66it/s]\n",
      "(  7/100) Loss: 0.605 | Acc: 82.455% (0.8245542949756888): 100%|██████████| 155/155 [00:07<00:00, 21.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss:0.521 acc_avg:76.558% acc:83.418% time:15s\n",
      "Testing loss:0.605 acc_avg:73.883% acc:82.455% time:7s [best test acc: 82.455%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "(  8/100) Loss: 0.497 | Acc: 84.151% (8267/9824): 100%|██████████| 307/307 [00:14<00:00, 20.70it/s]\n",
      "(  8/100) Loss: 0.628 | Acc: 82.658% (0.826580226904376): 100%|██████████| 155/155 [00:07<00:00, 21.20it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss:0.497 acc_avg:77.627% acc:84.151% time:15s\n",
      "Testing loss:0.628 acc_avg:74.949% acc:82.658% time:7s [best test acc: 82.658%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "(  9/100) Loss: 0.472 | Acc: 84.955% (8346/9824): 100%|██████████| 307/307 [00:14<00:00, 20.74it/s]\n",
      "(  9/100) Loss: 0.629 | Acc: 81.037% (0.8103727714748784): 100%|██████████| 155/155 [00:07<00:00, 20.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss:0.472 acc_avg:78.414% acc:84.955% time:15s\n",
      "Testing loss:0.629 acc_avg:74.331% acc:81.037% time:7s [best test acc: 82.658%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "( 10/100) Loss: 0.455 | Acc: 85.301% (8380/9824): 100%|██████████| 307/307 [00:14<00:00, 20.60it/s]\n",
      "( 10/100) Loss: 0.633 | Acc: 81.564% (0.8156401944894651): 100%|██████████| 155/155 [00:07<00:00, 21.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss:0.455 acc_avg:79.04% acc:85.301% time:15s\n",
      "Testing loss:0.633 acc_avg:75.566% acc:81.564% time:7s [best test acc: 82.658%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "( 11/100) Loss: 0.437 | Acc: 85.617% (8411/9824): 100%|██████████| 307/307 [00:14<00:00, 20.77it/s]\n",
      "( 11/100) Loss: 0.602 | Acc: 83.468% (0.8346839546191248): 100%|██████████| 155/155 [00:07<00:00, 21.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss:0.437 acc_avg:79.578% acc:85.617% time:15s\n",
      "Testing loss:0.602 acc_avg:75.753% acc:83.468% time:7s [best test acc: 83.468%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "( 12/100) Loss: 0.419 | Acc: 86.238% (8472/9824): 100%|██████████| 307/307 [00:14<00:00, 20.47it/s]\n",
      "( 12/100) Loss: 0.598 | Acc: 82.982% (0.8298217179902755): 100%|██████████| 155/155 [00:07<00:00, 21.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss:0.419 acc_avg:80.287% acc:86.238% time:15s\n",
      "Testing loss:0.598 acc_avg:77.019% acc:82.982% time:7s [best test acc: 83.468%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "( 13/100) Loss: 0.392 | Acc: 87.052% (8552/9824): 100%|██████████| 307/307 [00:14<00:00, 20.48it/s]\n",
      "( 13/100) Loss: 0.606 | Acc: 82.942% (0.8294165316045381): 100%|██████████| 155/155 [00:07<00:00, 21.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss:0.392 acc_avg:81.614% acc:87.052% time:15s\n",
      "Testing loss:0.606 acc_avg:76.36% acc:82.942% time:7s [best test acc: 83.468%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "( 14/100) Loss: 0.379 | Acc: 87.093% (8556/9824): 100%|██████████| 307/307 [00:14<00:00, 20.63it/s]\n",
      "( 14/100) Loss: 0.658 | Acc: 82.293% (0.8229335494327391): 100%|██████████| 155/155 [00:07<00:00, 21.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss:0.379 acc_avg:81.703% acc:87.093% time:15s\n",
      "Testing loss:0.658 acc_avg:75.873% acc:82.293% time:7s [best test acc: 83.468%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "( 15/100) Loss: 0.366 | Acc: 87.877% (8633/9824): 100%|██████████| 307/307 [00:14<00:00, 20.62it/s]\n",
      "( 15/100) Loss: 0.633 | Acc: 81.929% (0.8192868719611021): 100%|██████████| 155/155 [00:07<00:00, 21.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss:0.366 acc_avg:82.815% acc:87.877% time:15s\n",
      "Testing loss:0.633 acc_avg:76.569% acc:81.929% time:7s [best test acc: 83.468%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "( 16/100) Loss: 0.358 | Acc: 88.121% (8657/9824): 100%|██████████| 307/307 [00:14<00:00, 20.71it/s]\n",
      "( 16/100) Loss: 0.701 | Acc: 80.592% (0.8059157212317666): 100%|██████████| 155/155 [00:07<00:00, 21.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss:0.358 acc_avg:83.098% acc:88.121% time:15s\n",
      "Testing loss:0.701 acc_avg:76.195% acc:80.592% time:7s [best test acc: 83.468%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "( 17/100) Loss: 0.345 | Acc: 87.887% (8634/9824): 100%|██████████| 307/307 [00:14<00:00, 20.65it/s]\n",
      "( 17/100) Loss: 0.681 | Acc: 81.037% (0.8103727714748784): 100%|██████████| 155/155 [00:07<00:00, 21.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss:0.345 acc_avg:83.136% acc:87.887% time:15s\n",
      "Testing loss:0.681 acc_avg:75.566% acc:81.037% time:7s [best test acc: 83.468%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "( 18/100) Loss: 0.324 | Acc: 89.118% (8755/9824): 100%|██████████| 307/307 [00:14<00:00, 20.76it/s]\n",
      "( 18/100) Loss: 0.625 | Acc: 84.441% (0.8444084278768234): 100%|██████████| 155/155 [00:07<00:00, 21.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss:0.324 acc_avg:84.808% acc:89.118% time:15s\n",
      "Testing loss:0.625 acc_avg:77.041% acc:84.441% time:7s [best test acc: 84.441%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "( 19/100) Loss: 0.316 | Acc: 89.444% (8787/9824): 100%|██████████| 307/307 [00:14<00:00, 20.57it/s]\n",
      "( 19/100) Loss: 0.603 | Acc: 84.117% (0.8411669367909238): 100%|██████████| 155/155 [00:07<00:00, 21.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss:0.316 acc_avg:85.428% acc:89.444% time:15s\n",
      "Testing loss:0.603 acc_avg:77.54% acc:84.117% time:7s [best test acc: 84.441%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "( 20/100) Loss: 0.307 | Acc: 89.210% (8764/9824): 100%|██████████| 307/307 [00:14<00:00, 20.70it/s]\n",
      "( 20/100) Loss: 0.619 | Acc: 84.076% (0.8407617504051864): 100%|██████████| 155/155 [00:07<00:00, 20.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss:0.307 acc_avg:84.694% acc:89.21% time:15s\n",
      "Testing loss:0.619 acc_avg:79.733% acc:84.076% time:8s [best test acc: 84.441%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "( 21/100) Loss: 0.300 | Acc: 89.709% (8813/9824): 100%|██████████| 307/307 [00:14<00:00, 20.62it/s]\n",
      "( 21/100) Loss: 0.642 | Acc: 83.509% (0.8350891410048622): 100%|██████████| 155/155 [00:07<00:00, 21.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss:0.3 acc_avg:85.497% acc:89.709% time:15s\n",
      "Testing loss:0.642 acc_avg:76.457% acc:83.509% time:7s [best test acc: 84.441%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "( 22/100) Loss: 0.281 | Acc: 90.126% (8854/9824): 100%|██████████| 307/307 [00:14<00:00, 20.68it/s]\n",
      "( 22/100) Loss: 0.635 | Acc: 84.887% (0.8488654781199352): 100%|██████████| 155/155 [00:07<00:00, 20.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss:0.281 acc_avg:85.919% acc:90.126% time:15s\n",
      "Testing loss:0.635 acc_avg:78.877% acc:84.887% time:7s [best test acc: 84.887%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "( 23/100) Loss: 0.281 | Acc: 90.086% (8850/9824): 100%|██████████| 307/307 [00:14<00:00, 20.61it/s]\n",
      "( 23/100) Loss: 0.640 | Acc: 83.428% (0.8342787682333873): 100%|██████████| 155/155 [00:07<00:00, 21.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss:0.281 acc_avg:86.011% acc:90.086% time:15s\n",
      "Testing loss:0.64 acc_avg:77.428% acc:83.428% time:7s [best test acc: 84.887%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "( 24/100) Loss: 0.258 | Acc: 90.991% (8939/9824): 100%|██████████| 307/307 [00:14<00:00, 20.71it/s]\n",
      "( 24/100) Loss: 0.653 | Acc: 83.144% (0.8314424635332253): 100%|██████████| 155/155 [00:07<00:00, 21.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss:0.258 acc_avg:87.291% acc:90.991% time:15s\n",
      "Testing loss:0.653 acc_avg:77.244% acc:83.144% time:7s [best test acc: 84.887%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "( 25/100) Loss: 0.261 | Acc: 90.991% (8939/9824): 100%|██████████| 307/307 [00:14<00:00, 20.68it/s]\n",
      "( 25/100) Loss: 0.648 | Acc: 83.509% (0.8350891410048622): 100%|██████████| 155/155 [00:07<00:00, 21.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss:0.261 acc_avg:87.265% acc:90.991% time:15s\n",
      "Testing loss:0.648 acc_avg:78.34% acc:83.509% time:7s [best test acc: 84.887%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "( 26/100) Loss: 0.250 | Acc: 91.287% (8968/9824): 100%|██████████| 307/307 [00:14<00:00, 20.70it/s]\n",
      "( 26/100) Loss: 0.715 | Acc: 83.185% (0.8318476499189628): 100%|██████████| 155/155 [00:07<00:00, 20.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss:0.25 acc_avg:87.553% acc:91.287% time:15s\n",
      "Testing loss:0.715 acc_avg:77.554% acc:83.185% time:7s [best test acc: 84.887%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "( 27/100) Loss: 0.241 | Acc: 91.653% (9004/9824): 100%|██████████| 307/307 [00:15<00:00, 20.32it/s]\n",
      "( 27/100) Loss: 0.676 | Acc: 83.752% (0.8375202593192869): 100%|██████████| 155/155 [00:07<00:00, 21.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss:0.241 acc_avg:88.048% acc:91.653% time:15s\n",
      "Testing loss:0.676 acc_avg:78.299% acc:83.752% time:7s [best test acc: 84.887%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "( 28/100) Loss: 0.224 | Acc: 92.142% (9052/9824): 100%|██████████| 307/307 [00:14<00:00, 20.72it/s]\n",
      "( 28/100) Loss: 0.779 | Acc: 81.807% (0.8180713128038898): 100%|██████████| 155/155 [00:07<00:00, 21.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss:0.224 acc_avg:88.667% acc:92.142% time:15s\n",
      "Testing loss:0.779 acc_avg:78.049% acc:81.807% time:7s [best test acc: 84.887%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "( 29/100) Loss: 0.229 | Acc: 92.233% (9061/9824): 100%|██████████| 307/307 [00:14<00:00, 20.60it/s]\n",
      "( 29/100) Loss: 0.696 | Acc: 84.562% (0.8456239870340356): 100%|██████████| 155/155 [00:07<00:00, 20.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss:0.229 acc_avg:88.952% acc:92.233% time:15s\n",
      "Testing loss:0.696 acc_avg:79.644% acc:84.562% time:8s [best test acc: 84.887%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "( 30/100) Loss: 0.223 | Acc: 91.836% (9022/9824): 100%|██████████| 307/307 [00:14<00:00, 20.71it/s]\n",
      "( 30/100) Loss: 0.706 | Acc: 83.104% (0.8310372771474879): 100%|██████████| 155/155 [00:07<00:00, 21.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss:0.223 acc_avg:88.469% acc:91.836% time:15s\n",
      "Testing loss:0.706 acc_avg:77.323% acc:83.104% time:7s [best test acc: 84.887%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "( 31/100) Loss: 0.219 | Acc: 92.162% (9054/9824): 100%|██████████| 307/307 [00:14<00:00, 20.67it/s]\n",
      "( 31/100) Loss: 0.684 | Acc: 83.793% (0.8379254457050244): 100%|██████████| 155/155 [00:07<00:00, 21.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss:0.219 acc_avg:89.088% acc:92.162% time:15s\n",
      "Testing loss:0.684 acc_avg:78.252% acc:83.793% time:7s [best test acc: 84.887%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "( 32/100) Loss: 0.209 | Acc: 92.651% (9102/9824): 100%|██████████| 307/307 [00:15<00:00, 20.13it/s]\n",
      "( 32/100) Loss: 0.735 | Acc: 83.549% (0.8354943273905997): 100%|██████████| 155/155 [00:07<00:00, 21.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss:0.209 acc_avg:89.53% acc:92.651% time:15s\n",
      "Testing loss:0.735 acc_avg:78.598% acc:83.549% time:7s [best test acc: 84.887%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "( 33/100) Loss: 0.198 | Acc: 92.661% (9103/9824): 100%|██████████| 307/307 [00:15<00:00, 19.77it/s]\n",
      "( 33/100) Loss: 0.715 | Acc: 83.509% (0.8350891410048622): 100%|██████████| 155/155 [00:10<00:00, 14.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss:0.198 acc_avg:89.408% acc:92.661% time:16s\n",
      "Testing loss:0.715 acc_avg:77.453% acc:83.509% time:11s [best test acc: 84.887%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "( 34/100) Loss: 0.194 | Acc: 93.027% (9139/9824): 100%|██████████| 307/307 [00:21<00:00, 14.52it/s]\n",
      "( 34/100) Loss: 0.689 | Acc: 84.076% (0.8407617504051864): 100%|██████████| 155/155 [00:10<00:00, 14.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss:0.194 acc_avg:90.309% acc:93.027% time:21s\n",
      "Testing loss:0.689 acc_avg:79.915% acc:84.076% time:11s [best test acc: 84.887%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "( 35/100) Loss: 0.190 | Acc: 93.190% (9155/9824): 100%|██████████| 307/307 [00:22<00:00, 13.62it/s]\n",
      "( 35/100) Loss: 0.725 | Acc: 83.063% (0.8306320907617504): 100%|██████████| 155/155 [00:10<00:00, 14.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss:0.19 acc_avg:90.451% acc:93.19% time:23s\n",
      "Testing loss:0.725 acc_avg:78.987% acc:83.063% time:11s [best test acc: 84.887%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "( 36/100) Loss: 0.178 | Acc: 93.770% (9212/9824): 100%|██████████| 307/307 [00:22<00:00, 13.72it/s]\n",
      "( 36/100) Loss: 0.695 | Acc: 84.279% (0.8427876823338736): 100%|██████████| 155/155 [00:11<00:00, 13.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss:0.178 acc_avg:91.357% acc:93.77% time:23s\n",
      "Testing loss:0.695 acc_avg:77.47% acc:84.279% time:11s [best test acc: 84.887%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "( 37/100) Loss: 0.174 | Acc: 93.852% (9220/9824): 100%|██████████| 307/307 [00:21<00:00, 14.09it/s]\n",
      "( 37/100) Loss: 0.723 | Acc: 84.522% (0.8452188006482982): 100%|██████████| 155/155 [00:07<00:00, 20.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss:0.174 acc_avg:91.185% acc:93.852% time:22s\n",
      "Testing loss:0.723 acc_avg:79.249% acc:84.522% time:8s [best test acc: 84.887%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "( 38/100) Loss: 0.169 | Acc: 93.618% (9197/9824): 100%|██████████| 307/307 [00:21<00:00, 14.19it/s]\n",
      "( 38/100) Loss: 0.747 | Acc: 84.157% (0.8415721231766613): 100%|██████████| 155/155 [00:07<00:00, 21.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss:0.169 acc_avg:90.684% acc:93.618% time:22s\n",
      "Testing loss:0.747 acc_avg:78.173% acc:84.157% time:7s [best test acc: 84.887%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "( 39/100) Loss: 0.169 | Acc: 93.933% (9228/9824): 100%|██████████| 307/307 [00:14<00:00, 20.50it/s]\n",
      "( 39/100) Loss: 0.708 | Acc: 84.522% (0.8452188006482982): 100%|██████████| 155/155 [00:07<00:00, 21.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss:0.169 acc_avg:91.58% acc:93.933% time:15s\n",
      "Testing loss:0.708 acc_avg:78.719% acc:84.522% time:7s [best test acc: 84.887%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "( 40/100) Loss: 0.158 | Acc: 93.882% (9223/9824): 100%|██████████| 307/307 [00:15<00:00, 20.41it/s]\n",
      "( 40/100) Loss: 0.770 | Acc: 84.036% (0.8403565640194489): 100%|██████████| 155/155 [00:07<00:00, 20.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss:0.158 acc_avg:91.261% acc:93.882% time:15s\n",
      "Testing loss:0.77 acc_avg:78.783% acc:84.036% time:7s [best test acc: 84.887%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "( 41/100) Loss: 0.152 | Acc: 94.412% (9275/9824): 100%|██████████| 307/307 [00:15<00:00, 20.27it/s]\n",
      "( 41/100) Loss: 0.761 | Acc: 84.076% (0.8407617504051864): 100%|██████████| 155/155 [00:07<00:00, 21.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss:0.152 acc_avg:92.219% acc:94.412% time:15s\n",
      "Testing loss:0.761 acc_avg:79.456% acc:84.076% time:7s [best test acc: 84.887%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "( 42/100) Loss: 0.151 | Acc: 94.361% (9270/9824): 100%|██████████| 307/307 [00:15<00:00, 20.18it/s]\n",
      "( 42/100) Loss: 0.722 | Acc: 84.968% (0.8496758508914101): 100%|██████████| 155/155 [00:07<00:00, 21.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss:0.151 acc_avg:91.878% acc:94.361% time:15s\n",
      "Testing loss:0.722 acc_avg:79.453% acc:84.968% time:7s [best test acc: 84.968%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "( 43/100) Loss: 0.141 | Acc: 94.717% (9305/9824): 100%|██████████| 307/307 [00:15<00:00, 20.22it/s]\n",
      "( 43/100) Loss: 0.780 | Acc: 83.630% (0.8363047001620746): 100%|██████████| 155/155 [00:07<00:00, 20.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss:0.141 acc_avg:92.441% acc:94.717% time:15s\n",
      "Testing loss:0.78 acc_avg:78.403% acc:83.63% time:7s [best test acc: 84.968%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "( 44/100) Loss: 0.139 | Acc: 95.083% (9341/9824): 100%|██████████| 307/307 [00:15<00:00, 20.36it/s]\n",
      "( 44/100) Loss: 0.784 | Acc: 83.347% (0.8334683954619124): 100%|██████████| 155/155 [00:07<00:00, 20.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss:0.139 acc_avg:93.123% acc:95.083% time:15s\n",
      "Testing loss:0.784 acc_avg:77.808% acc:83.347% time:7s [best test acc: 84.968%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "( 45/100) Loss: 0.134 | Acc: 95.094% (9342/9824): 100%|██████████| 307/307 [00:15<00:00, 20.34it/s]\n",
      "( 45/100) Loss: 0.811 | Acc: 84.198% (0.8419773095623987): 100%|██████████| 155/155 [00:07<00:00, 20.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss:0.134 acc_avg:92.982% acc:95.094% time:15s\n",
      "Testing loss:0.811 acc_avg:79.107% acc:84.198% time:7s [best test acc: 84.968%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "( 46/100) Loss: 0.129 | Acc: 95.155% (9348/9824): 100%|██████████| 307/307 [00:15<00:00, 20.25it/s]\n",
      "( 46/100) Loss: 0.817 | Acc: 83.549% (0.8354943273905997): 100%|██████████| 155/155 [00:07<00:00, 20.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss:0.129 acc_avg:93.399% acc:95.155% time:15s\n",
      "Testing loss:0.817 acc_avg:78.444% acc:83.549% time:8s [best test acc: 84.968%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "( 47/100) Loss: 0.123 | Acc: 95.491% (9381/9824): 100%|██████████| 307/307 [00:15<00:00, 20.05it/s]\n",
      "( 47/100) Loss: 0.816 | Acc: 83.995% (0.8399513776337115): 100%|██████████| 155/155 [00:07<00:00, 21.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss:0.123 acc_avg:93.656% acc:95.491% time:15s\n",
      "Testing loss:0.816 acc_avg:79.315% acc:83.995% time:7s [best test acc: 84.968%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "( 48/100) Loss: 0.133 | Acc: 95.318% (9364/9824): 100%|██████████| 307/307 [00:15<00:00, 20.37it/s]\n",
      "( 48/100) Loss: 0.811 | Acc: 84.360% (0.8435980551053485): 100%|██████████| 155/155 [00:07<00:00, 20.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss:0.133 acc_avg:93.384% acc:95.318% time:15s\n",
      "Testing loss:0.811 acc_avg:79.57% acc:84.36% time:7s [best test acc: 84.968%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "( 49/100) Loss: 0.115 | Acc: 95.765% (9408/9824): 100%|██████████| 307/307 [00:15<00:00, 20.07it/s]\n",
      "( 49/100) Loss: 0.797 | Acc: 83.549% (0.8354943273905997): 100%|██████████| 155/155 [00:07<00:00, 20.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss:0.115 acc_avg:93.977% acc:95.765% time:15s\n",
      "Testing loss:0.797 acc_avg:78.845% acc:83.549% time:7s [best test acc: 84.968%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "( 50/100) Loss: 0.115 | Acc: 95.623% (9394/9824): 100%|██████████| 307/307 [00:15<00:00, 20.20it/s]\n",
      "( 50/100) Loss: 0.825 | Acc: 83.995% (0.8399513776337115): 100%|██████████| 155/155 [00:07<00:00, 20.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss:0.115 acc_avg:93.808% acc:95.623% time:15s\n",
      "Testing loss:0.825 acc_avg:78.548% acc:83.995% time:8s [best test acc: 84.968%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "( 51/100) Loss: 0.103 | Acc: 96.173% (9448/9824): 100%|██████████| 307/307 [00:15<00:00, 20.37it/s]\n",
      "( 51/100) Loss: 0.824 | Acc: 84.036% (0.8403565640194489): 100%|██████████| 155/155 [00:07<00:00, 21.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss:0.103 acc_avg:94.598% acc:96.173% time:15s\n",
      "Testing loss:0.824 acc_avg:78.97% acc:84.036% time:7s [best test acc: 84.968%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "( 52/100) Loss: 0.108 | Acc: 95.786% (9410/9824): 100%|██████████| 307/307 [00:14<00:00, 20.67it/s]\n",
      "( 52/100) Loss: 0.851 | Acc: 83.387% (0.8338735818476499): 100%|██████████| 155/155 [00:07<00:00, 20.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss:0.108 acc_avg:93.945% acc:95.786% time:15s\n",
      "Testing loss:0.851 acc_avg:78.225% acc:83.387% time:7s [best test acc: 84.968%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "( 53/100) Loss: 0.101 | Acc: 96.325% (9463/9824): 100%|██████████| 307/307 [00:15<00:00, 20.08it/s]\n",
      "( 53/100) Loss: 0.841 | Acc: 84.441% (0.8444084278768234): 100%|██████████| 155/155 [00:07<00:00, 20.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss:0.101 acc_avg:94.765% acc:96.325% time:15s\n",
      "Testing loss:0.841 acc_avg:79.852% acc:84.441% time:7s [best test acc: 84.968%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "( 54/100) Loss: 0.098 | Acc: 96.447% (9475/9824): 100%|██████████| 307/307 [00:15<00:00, 20.22it/s]\n",
      "( 54/100) Loss: 0.828 | Acc: 85.049% (0.850486223662885): 100%|██████████| 155/155 [00:07<00:00, 20.71it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss:0.098 acc_avg:94.96% acc:96.447% time:15s\n",
      "Testing loss:0.828 acc_avg:79.261% acc:85.049% time:7s [best test acc: 85.049%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "( 55/100) Loss: 0.092 | Acc: 96.559% (9486/9824): 100%|██████████| 307/307 [00:15<00:00, 20.40it/s]\n",
      "( 55/100) Loss: 0.849 | Acc: 83.590% (0.8358995137763371): 100%|██████████| 155/155 [00:07<00:00, 20.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss:0.092 acc_avg:94.921% acc:96.559% time:15s\n",
      "Testing loss:0.849 acc_avg:77.82% acc:83.59% time:7s [best test acc: 85.049%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "( 56/100) Loss: 0.090 | Acc: 96.743% (9504/9824): 100%|██████████| 307/307 [00:14<00:00, 20.53it/s]\n",
      "( 56/100) Loss: 0.848 | Acc: 83.752% (0.8375202593192869): 100%|██████████| 155/155 [00:07<00:00, 20.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss:0.09 acc_avg:95.497% acc:96.743% time:15s\n",
      "Testing loss:0.848 acc_avg:78.807% acc:83.752% time:7s [best test acc: 85.049%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "( 57/100) Loss: 0.085 | Acc: 96.824% (9512/9824): 100%|██████████| 307/307 [00:15<00:00, 19.94it/s]\n",
      "( 57/100) Loss: 0.853 | Acc: 84.198% (0.8419773095623987): 100%|██████████| 155/155 [00:07<00:00, 21.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss:0.085 acc_avg:95.594% acc:96.824% time:15s\n",
      "Testing loss:0.853 acc_avg:78.562% acc:84.198% time:7s [best test acc: 85.049%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "( 58/100) Loss: 0.082 | Acc: 96.926% (9522/9824): 100%|██████████| 307/307 [00:14<00:00, 20.55it/s]\n",
      "( 58/100) Loss: 0.876 | Acc: 84.076% (0.8407617504051864): 100%|██████████| 155/155 [00:07<00:00, 21.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss:0.082 acc_avg:95.704% acc:96.926% time:15s\n",
      "Testing loss:0.876 acc_avg:79.794% acc:84.076% time:7s [best test acc: 85.049%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "( 59/100) Loss: 0.081 | Acc: 96.743% (9504/9824): 100%|██████████| 307/307 [00:15<00:00, 19.89it/s]\n",
      "( 59/100) Loss: 0.852 | Acc: 84.076% (0.8407617504051864): 100%|██████████| 155/155 [00:07<00:00, 20.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss:0.081 acc_avg:95.491% acc:96.743% time:15s\n",
      "Testing loss:0.852 acc_avg:78.495% acc:84.076% time:7s [best test acc: 85.049%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "( 60/100) Loss: 0.077 | Acc: 97.119% (9541/9824): 100%|██████████| 307/307 [00:15<00:00, 20.15it/s]\n",
      "( 60/100) Loss: 0.849 | Acc: 84.562% (0.8456239870340356): 100%|██████████| 155/155 [00:07<00:00, 20.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss:0.077 acc_avg:95.874% acc:97.119% time:15s\n",
      "Testing loss:0.849 acc_avg:80.719% acc:84.562% time:7s [best test acc: 85.049%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "( 61/100) Loss: 0.074 | Acc: 97.129% (9542/9824): 100%|██████████| 307/307 [00:15<00:00, 20.36it/s]\n",
      "( 61/100) Loss: 0.856 | Acc: 84.968% (0.8496758508914101): 100%|██████████| 155/155 [00:07<00:00, 20.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss:0.074 acc_avg:96.054% acc:97.129% time:15s\n",
      "Testing loss:0.856 acc_avg:79.866% acc:84.968% time:7s [best test acc: 85.049%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "( 62/100) Loss: 0.077 | Acc: 97.160% (9545/9824): 100%|██████████| 307/307 [00:15<00:00, 20.09it/s]\n",
      "( 62/100) Loss: 0.869 | Acc: 84.806% (0.8480551053484603): 100%|██████████| 155/155 [00:07<00:00, 20.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss:0.077 acc_avg:95.839% acc:97.16% time:15s\n",
      "Testing loss:0.869 acc_avg:79.519% acc:84.806% time:8s [best test acc: 85.049%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "( 63/100) Loss: 0.073 | Acc: 97.170% (9546/9824): 100%|██████████| 307/307 [00:15<00:00, 20.19it/s]\n",
      "( 63/100) Loss: 0.891 | Acc: 83.793% (0.8379254457050244): 100%|██████████| 155/155 [00:07<00:00, 21.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss:0.073 acc_avg:95.981% acc:97.17% time:15s\n",
      "Testing loss:0.891 acc_avg:78.795% acc:83.793% time:7s [best test acc: 85.049%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "( 64/100) Loss: 0.074 | Acc: 97.201% (9549/9824): 100%|██████████| 307/307 [00:15<00:00, 20.13it/s]\n",
      "( 64/100) Loss: 0.884 | Acc: 84.765% (0.8476499189627229): 100%|██████████| 155/155 [00:07<00:00, 20.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss:0.074 acc_avg:96.075% acc:97.201% time:15s\n",
      "Testing loss:0.884 acc_avg:79.899% acc:84.765% time:7s [best test acc: 85.049%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "( 65/100) Loss: 0.065 | Acc: 97.547% (9583/9824): 100%|██████████| 307/307 [00:15<00:00, 20.40it/s]\n",
      "( 65/100) Loss: 0.889 | Acc: 84.279% (0.8427876823338736): 100%|██████████| 155/155 [00:07<00:00, 20.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss:0.065 acc_avg:96.512% acc:97.547% time:15s\n",
      "Testing loss:0.889 acc_avg:79.049% acc:84.279% time:8s [best test acc: 85.049%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "( 66/100) Loss: 0.064 | Acc: 97.537% (9582/9824): 100%|██████████| 307/307 [00:14<00:00, 20.58it/s]\n",
      "( 66/100) Loss: 0.872 | Acc: 84.481% (0.8448136142625607): 100%|██████████| 155/155 [00:07<00:00, 21.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss:0.064 acc_avg:96.446% acc:97.537% time:15s\n",
      "Testing loss:0.872 acc_avg:79.412% acc:84.481% time:7s [best test acc: 85.049%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "( 67/100) Loss: 0.061 | Acc: 97.761% (9604/9824): 100%|██████████| 307/307 [00:15<00:00, 20.10it/s]\n",
      "( 67/100) Loss: 0.913 | Acc: 84.319% (0.843192868719611): 100%|██████████| 155/155 [00:07<00:00, 20.83it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss:0.061 acc_avg:96.931% acc:97.761% time:15s\n",
      "Testing loss:0.913 acc_avg:79.52% acc:84.319% time:7s [best test acc: 85.049%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "( 68/100) Loss: 0.061 | Acc: 97.761% (9604/9824): 100%|██████████| 307/307 [00:15<00:00, 20.23it/s]\n",
      "( 68/100) Loss: 0.881 | Acc: 85.049% (0.850486223662885): 100%|██████████| 155/155 [00:07<00:00, 21.13it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss:0.061 acc_avg:96.83% acc:97.761% time:15s\n",
      "Testing loss:0.881 acc_avg:80.178% acc:85.049% time:7s [best test acc: 85.049%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "( 69/100) Loss: 0.056 | Acc: 97.822% (9610/9824): 100%|██████████| 307/307 [00:15<00:00, 20.31it/s]\n",
      "( 69/100) Loss: 0.903 | Acc: 84.117% (0.8411669367909238): 100%|██████████| 155/155 [00:07<00:00, 21.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss:0.056 acc_avg:96.825% acc:97.822% time:15s\n",
      "Testing loss:0.903 acc_avg:79.735% acc:84.117% time:7s [best test acc: 85.049%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "( 70/100) Loss: 0.050 | Acc: 98.208% (9648/9824): 100%|██████████| 307/307 [00:15<00:00, 20.31it/s]\n",
      "( 70/100) Loss: 0.939 | Acc: 84.036% (0.8403565640194489): 100%|██████████| 155/155 [00:07<00:00, 20.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss:0.05 acc_avg:97.421% acc:98.208% time:15s\n",
      "Testing loss:0.939 acc_avg:79.028% acc:84.036% time:7s [best test acc: 85.049%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "( 71/100) Loss: 0.054 | Acc: 97.954% (9623/9824): 100%|██████████| 307/307 [00:15<00:00, 20.37it/s]\n",
      "( 71/100) Loss: 0.943 | Acc: 84.279% (0.8427876823338736): 100%|██████████| 155/155 [00:07<00:00, 20.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss:0.054 acc_avg:96.933% acc:97.954% time:15s\n",
      "Testing loss:0.943 acc_avg:79.67% acc:84.279% time:7s [best test acc: 85.049%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "( 72/100) Loss: 0.053 | Acc: 97.954% (9623/9824): 100%|██████████| 307/307 [00:15<00:00, 20.21it/s]\n",
      "( 72/100) Loss: 0.909 | Acc: 84.238% (0.8423824959481362): 100%|██████████| 155/155 [00:07<00:00, 20.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss:0.053 acc_avg:97.036% acc:97.954% time:15s\n",
      "Testing loss:0.909 acc_avg:79.053% acc:84.238% time:7s [best test acc: 85.049%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "( 73/100) Loss: 0.051 | Acc: 97.995% (9627/9824): 100%|██████████| 307/307 [00:15<00:00, 20.28it/s]\n",
      "( 73/100) Loss: 0.892 | Acc: 84.968% (0.8496758508914101): 100%|██████████| 155/155 [00:07<00:00, 21.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss:0.051 acc_avg:97.141% acc:97.995% time:15s\n",
      "Testing loss:0.892 acc_avg:80.282% acc:84.968% time:7s [best test acc: 85.049%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "( 74/100) Loss: 0.049 | Acc: 98.229% (9650/9824): 100%|██████████| 307/307 [00:15<00:00, 20.27it/s]\n",
      "( 74/100) Loss: 0.924 | Acc: 83.955% (0.839546191247974): 100%|██████████| 155/155 [00:07<00:00, 20.97it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss:0.049 acc_avg:97.332% acc:98.229% time:15s\n",
      "Testing loss:0.924 acc_avg:78.887% acc:83.955% time:7s [best test acc: 85.049%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "( 75/100) Loss: 0.047 | Acc: 98.188% (9646/9824): 100%|██████████| 307/307 [00:14<00:00, 20.56it/s]\n",
      "( 75/100) Loss: 0.926 | Acc: 84.522% (0.8452188006482982): 100%|██████████| 155/155 [00:07<00:00, 21.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss:0.047 acc_avg:97.396% acc:98.188% time:15s\n",
      "Testing loss:0.926 acc_avg:79.736% acc:84.522% time:7s [best test acc: 85.049%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "( 76/100) Loss: 0.042 | Acc: 98.320% (9659/9824): 100%|██████████| 307/307 [00:14<00:00, 20.58it/s]\n",
      "( 76/100) Loss: 0.910 | Acc: 85.008% (0.8500810372771475): 100%|██████████| 155/155 [00:07<00:00, 21.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss:0.042 acc_avg:97.687% acc:98.32% time:15s\n",
      "Testing loss:0.91 acc_avg:79.978% acc:85.008% time:7s [best test acc: 85.049%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "( 77/100) Loss: 0.048 | Acc: 98.035% (9631/9824): 100%|██████████| 307/307 [00:14<00:00, 20.64it/s]\n",
      "( 77/100) Loss: 0.957 | Acc: 84.238% (0.8423824959481362): 100%|██████████| 155/155 [00:07<00:00, 21.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss:0.048 acc_avg:97.347% acc:98.035% time:15s\n",
      "Testing loss:0.957 acc_avg:79.79% acc:84.238% time:7s [best test acc: 85.049%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "( 78/100) Loss: 0.043 | Acc: 98.310% (9658/9824): 100%|██████████| 307/307 [00:14<00:00, 20.88it/s]\n",
      "( 78/100) Loss: 0.950 | Acc: 84.684% (0.846839546191248): 100%|██████████| 155/155 [00:07<00:00, 21.06it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss:0.043 acc_avg:97.652% acc:98.31% time:15s\n",
      "Testing loss:0.95 acc_avg:80.257% acc:84.684% time:7s [best test acc: 85.049%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "( 79/100) Loss: 0.041 | Acc: 98.341% (9661/9824): 100%|██████████| 307/307 [00:14<00:00, 20.70it/s]\n",
      "( 79/100) Loss: 0.901 | Acc: 85.049% (0.850486223662885): 100%|██████████| 155/155 [00:07<00:00, 21.12it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss:0.041 acc_avg:97.607% acc:98.341% time:15s\n",
      "Testing loss:0.901 acc_avg:80.615% acc:85.049% time:7s [best test acc: 85.049%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "( 80/100) Loss: 0.042 | Acc: 98.432% (9670/9824): 100%|██████████| 307/307 [00:14<00:00, 20.69it/s]\n",
      "( 80/100) Loss: 0.967 | Acc: 84.522% (0.8452188006482982): 100%|██████████| 155/155 [00:07<00:00, 21.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss:0.042 acc_avg:97.759% acc:98.432% time:15s\n",
      "Testing loss:0.967 acc_avg:79.936% acc:84.522% time:7s [best test acc: 85.049%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "( 81/100) Loss: 0.042 | Acc: 98.382% (9665/9824): 100%|██████████| 307/307 [00:15<00:00, 19.83it/s]\n",
      "( 81/100) Loss: 0.946 | Acc: 84.887% (0.8488654781199352): 100%|██████████| 155/155 [00:07<00:00, 21.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss:0.042 acc_avg:97.828% acc:98.382% time:15s\n",
      "Testing loss:0.946 acc_avg:80.415% acc:84.887% time:7s [best test acc: 85.049%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "( 82/100) Loss: 0.043 | Acc: 98.280% (9655/9824): 100%|██████████| 307/307 [00:14<00:00, 20.69it/s]\n",
      "( 82/100) Loss: 0.933 | Acc: 84.765% (0.8476499189627229): 100%|██████████| 155/155 [00:07<00:00, 21.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss:0.043 acc_avg:97.493% acc:98.28% time:15s\n",
      "Testing loss:0.933 acc_avg:80.303% acc:84.765% time:7s [best test acc: 85.049%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "( 83/100) Loss: 0.038 | Acc: 98.585% (9685/9824): 100%|██████████| 307/307 [00:15<00:00, 20.31it/s]\n",
      "( 83/100) Loss: 0.946 | Acc: 85.211% (0.8521069692058347): 100%|██████████| 155/155 [00:07<00:00, 21.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss:0.038 acc_avg:97.909% acc:98.585% time:15s\n",
      "Testing loss:0.946 acc_avg:80.315% acc:85.211% time:7s [best test acc: 85.211%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "( 84/100) Loss: 0.040 | Acc: 98.483% (9675/9824): 100%|██████████| 307/307 [00:14<00:00, 20.64it/s]\n",
      "( 84/100) Loss: 0.952 | Acc: 84.765% (0.8476499189627229): 100%|██████████| 155/155 [00:07<00:00, 21.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss:0.04 acc_avg:97.85% acc:98.483% time:15s\n",
      "Testing loss:0.952 acc_avg:80.011% acc:84.765% time:7s [best test acc: 85.211%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "( 85/100) Loss: 0.038 | Acc: 98.412% (9668/9824): 100%|██████████| 307/307 [00:14<00:00, 20.75it/s]\n",
      "( 85/100) Loss: 0.968 | Acc: 84.927% (0.8492706645056726): 100%|██████████| 155/155 [00:07<00:00, 21.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss:0.038 acc_avg:97.735% acc:98.412% time:15s\n",
      "Testing loss:0.968 acc_avg:80.224% acc:84.927% time:7s [best test acc: 85.211%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "( 86/100) Loss: 0.037 | Acc: 98.636% (9690/9824): 100%|██████████| 307/307 [00:14<00:00, 20.80it/s]\n",
      "( 86/100) Loss: 0.942 | Acc: 84.806% (0.8480551053484603): 100%|██████████| 155/155 [00:07<00:00, 21.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss:0.037 acc_avg:98.019% acc:98.636% time:15s\n",
      "Testing loss:0.942 acc_avg:80.561% acc:84.806% time:7s [best test acc: 85.211%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "( 87/100) Loss: 0.037 | Acc: 98.504% (9677/9824): 100%|██████████| 307/307 [00:15<00:00, 19.90it/s]\n",
      "( 87/100) Loss: 0.968 | Acc: 84.522% (0.8452188006482982): 100%|██████████| 155/155 [00:07<00:00, 21.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss:0.037 acc_avg:97.91% acc:98.504% time:15s\n",
      "Testing loss:0.968 acc_avg:80.037% acc:84.522% time:7s [best test acc: 85.211%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "( 88/100) Loss: 0.038 | Acc: 98.443% (9671/9824): 100%|██████████| 307/307 [00:14<00:00, 20.77it/s]\n",
      "( 88/100) Loss: 0.913 | Acc: 85.332% (0.853322528363047): 100%|██████████| 155/155 [00:07<00:00, 21.03it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss:0.038 acc_avg:97.713% acc:98.443% time:15s\n",
      "Testing loss:0.913 acc_avg:80.181% acc:85.332% time:7s [best test acc: 85.332%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "( 89/100) Loss: 0.037 | Acc: 98.453% (9672/9824): 100%|██████████| 307/307 [00:14<00:00, 20.71it/s]\n",
      "( 89/100) Loss: 0.961 | Acc: 84.643% (0.8464343598055105): 100%|██████████| 155/155 [00:07<00:00, 20.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss:0.037 acc_avg:97.739% acc:98.453% time:15s\n",
      "Testing loss:0.961 acc_avg:80.228% acc:84.643% time:7s [best test acc: 85.332%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "( 90/100) Loss: 0.037 | Acc: 98.585% (9685/9824): 100%|██████████| 307/307 [00:14<00:00, 20.54it/s]\n",
      "( 90/100) Loss: 0.938 | Acc: 85.049% (0.850486223662885): 100%|██████████| 155/155 [00:07<00:00, 20.86it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss:0.037 acc_avg:98.044% acc:98.585% time:15s\n",
      "Testing loss:0.938 acc_avg:80.699% acc:85.049% time:7s [best test acc: 85.332%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "( 91/100) Loss: 0.034 | Acc: 98.758% (9702/9824): 100%|██████████| 307/307 [00:14<00:00, 20.73it/s]\n",
      "( 91/100) Loss: 0.947 | Acc: 85.008% (0.8500810372771475): 100%|██████████| 155/155 [00:07<00:00, 21.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss:0.034 acc_avg:98.243% acc:98.758% time:15s\n",
      "Testing loss:0.947 acc_avg:80.182% acc:85.008% time:7s [best test acc: 85.332%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "( 92/100) Loss: 0.034 | Acc: 98.697% (9696/9824): 100%|██████████| 307/307 [00:14<00:00, 20.85it/s]\n",
      "( 92/100) Loss: 0.951 | Acc: 85.373% (0.8537277147487844): 100%|██████████| 155/155 [00:07<00:00, 21.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss:0.034 acc_avg:98.056% acc:98.697% time:15s\n",
      "Testing loss:0.951 acc_avg:81.135% acc:85.373% time:7s [best test acc: 85.373%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "( 93/100) Loss: 0.035 | Acc: 98.646% (9691/9824): 100%|██████████| 307/307 [00:14<00:00, 21.49it/s]\n",
      "( 93/100) Loss: 0.960 | Acc: 84.887% (0.8488654781199352): 100%|██████████| 155/155 [00:06<00:00, 23.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss:0.035 acc_avg:98.148% acc:98.646% time:14s\n",
      "Testing loss:0.96 acc_avg:80.511% acc:84.887% time:7s [best test acc: 85.373%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "( 94/100) Loss: 0.037 | Acc: 98.616% (9688/9824): 100%|██████████| 307/307 [00:14<00:00, 21.84it/s]\n",
      "( 94/100) Loss: 0.975 | Acc: 84.765% (0.8476499189627229): 100%|██████████| 155/155 [00:07<00:00, 21.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss:0.037 acc_avg:98.055% acc:98.616% time:14s\n",
      "Testing loss:0.975 acc_avg:80.503% acc:84.765% time:7s [best test acc: 85.373%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "( 95/100) Loss: 0.038 | Acc: 98.432% (9670/9824): 100%|██████████| 307/307 [00:14<00:00, 20.52it/s]\n",
      "( 95/100) Loss: 0.948 | Acc: 85.049% (0.850486223662885): 100%|██████████| 155/155 [00:07<00:00, 21.19it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss:0.038 acc_avg:97.689% acc:98.432% time:15s\n",
      "Testing loss:0.948 acc_avg:80.619% acc:85.049% time:7s [best test acc: 85.373%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "( 96/100) Loss: 0.033 | Acc: 98.667% (9693/9824): 100%|██████████| 307/307 [00:14<00:00, 20.73it/s]\n",
      "( 96/100) Loss: 0.958 | Acc: 84.806% (0.8480551053484603): 100%|██████████| 155/155 [00:07<00:00, 21.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss:0.033 acc_avg:98.128% acc:98.667% time:15s\n",
      "Testing loss:0.958 acc_avg:80.673% acc:84.806% time:7s [best test acc: 85.373%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "( 97/100) Loss: 0.034 | Acc: 98.738% (9700/9824): 100%|██████████| 307/307 [00:14<00:00, 20.78it/s]\n",
      "( 97/100) Loss: 0.950 | Acc: 85.049% (0.850486223662885): 100%|██████████| 155/155 [00:07<00:00, 21.19it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss:0.034 acc_avg:98.222% acc:98.738% time:15s\n",
      "Testing loss:0.95 acc_avg:80.419% acc:85.049% time:7s [best test acc: 85.373%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "( 98/100) Loss: 0.033 | Acc: 98.717% (9698/9824): 100%|██████████| 307/307 [00:14<00:00, 20.64it/s]\n",
      "( 98/100) Loss: 0.937 | Acc: 84.968% (0.8496758508914101): 100%|██████████| 155/155 [00:07<00:00, 21.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss:0.033 acc_avg:98.162% acc:98.717% time:15s\n",
      "Testing loss:0.937 acc_avg:80.361% acc:84.968% time:7s [best test acc: 85.373%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "( 99/100) Loss: 0.035 | Acc: 98.667% (9693/9824): 100%|██████████| 307/307 [00:14<00:00, 20.84it/s]\n",
      "( 99/100) Loss: 0.970 | Acc: 84.846% (0.8484602917341977): 100%|██████████| 155/155 [00:07<00:00, 20.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss:0.035 acc_avg:98.118% acc:98.667% time:15s\n",
      "Testing loss:0.97 acc_avg:80.682% acc:84.846% time:7s [best test acc: 85.373%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Training (Taken from PointMLP-PyTorch)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "num_epochs = 100 # Number of epochs\n",
    "eval_every = 10 # Evaluate every 'eval_every' epochs\n",
    "max_lr = 0.1 # Maximum learning rate\n",
    "min_lr = 0.001 # Minimum learning rate\n",
    "\n",
    "best_test_acc = 0.  # best test accuracy\n",
    "best_train_acc = 0.\n",
    "best_test_acc_avg = 0.\n",
    "best_train_acc_avg = 0.\n",
    "best_test_loss = float(\"inf\")\n",
    "best_train_loss = float(\"inf\")\n",
    "start_epoch = 0  # start from epoch 0 or last checkpoint epoch\n",
    "\n",
    "# Model\n",
    "net = MomentNet(3, [512, 256, 128], 40, degree = 12, poly_type = 'chebyshev').to(device)\n",
    "print(net.num_poly)\n",
    "\n",
    "# Optimizer\n",
    "optimizer = torch.optim.SGD(net.parameters(), lr=max_lr, momentum=0.9, weight_decay=0)\n",
    "scheduler = CosineAnnealingLR(optimizer, num_epochs, eta_min=min_lr, last_epoch=start_epoch - 1)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "for epoch in range(start_epoch, num_epochs):\n",
    "    train_out = train(net, train_loader, optimizer, criterion, epoch, num_epochs, device)  # {\"loss\", \"acc\", \"acc_avg\", \"time\"}\n",
    "    test_out = validate(net, test_loader, criterion, epoch, num_epochs, device)\n",
    "    scheduler.step()\n",
    "    if test_out[\"acc\"] > best_test_acc:\n",
    "        best_test_acc = test_out[\"acc\"]\n",
    "        is_best = True\n",
    "    else:\n",
    "        is_best = False\n",
    "\n",
    "    best_test_acc = test_out[\"acc\"] if (test_out[\"acc\"] > best_test_acc) else best_test_acc\n",
    "    best_train_acc = train_out[\"acc\"] if (train_out[\"acc\"] > best_train_acc) else best_train_acc\n",
    "    best_test_acc_avg = test_out[\"acc_avg\"] if (test_out[\"acc_avg\"] > best_test_acc_avg) else best_test_acc_avg\n",
    "    best_train_acc_avg = train_out[\"acc_avg\"] if (train_out[\"acc_avg\"] > best_train_acc_avg) else best_train_acc_avg\n",
    "    best_test_loss = test_out[\"loss\"] if (test_out[\"loss\"] < best_test_loss) else best_test_loss\n",
    "    best_train_loss = train_out[\"loss\"] if (train_out[\"loss\"] < best_train_loss) else best_train_loss\n",
    "    \n",
    "    print(\n",
    "        f\"Training loss:{train_out['loss']} acc_avg:{train_out['acc_avg']}% acc:{train_out['acc']}% time:{train_out['time']}s\")\n",
    "    print(\n",
    "        f\"Testing loss:{test_out['loss']} acc_avg:{test_out['acc_avg']}% \"\n",
    "        f\"acc:{test_out['acc']}% time:{test_out['time']}s [best test acc: {best_test_acc}%]\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch3d",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
