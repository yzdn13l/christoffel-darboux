{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "from itertools import combinations_with_replacement\n",
    "from numpy.linalg import qr, norm\n",
    "import open3d as o3d\n",
    "import datetime\n",
    "from utils import Logger, mkdir_p, progress_bar, save_model, save_args, cal_loss\n",
    "\n",
    "import sklearn.metrics as metrics\n",
    "from data import ModelNet40\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "import sklearn.metrics as metrics\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# degree = 10\n",
    "# d = 3\n",
    "# num_poly = math.comb(degree + d, d)\n",
    "# print('num_poly:', num_poly)\n",
    "# device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# exponents = []\n",
    "# # Generate all multi-indices with total degree up to 'degree'\n",
    "# for total_degree in range(degree + 1):\n",
    "#     for exps in combinations_with_replacement(range(d), total_degree):\n",
    "#         exp = torch.zeros(d, dtype=int, device=device)\n",
    "#         for var in exps:\n",
    "#             exp[var] += 1\n",
    "#         exponents.append(exp)\n",
    "# M = len(exponents)\n",
    "# print('Number of monomials:', M)\n",
    "# print('Monomials:', exponents[:10])\n",
    "\n",
    "# exponents = torch.zeros(num_poly, d, dtype=int, device=device)\n",
    "# i = 0\n",
    "# for total_degree in range(degree + 1):\n",
    "#     for exps in combinations_with_replacement(range(d), total_degree):\n",
    "#         for var in exps:\n",
    "#             exponents[i, var] += 1\n",
    "#         i += 1\n",
    "\n",
    "# print('Monomials:', exponents[:10])\n",
    "# print(exponents.shape, exponents.dtype, exponents.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import combinations_with_replacement\n",
    "\n",
    "def generate_exponents(d, degree):\n",
    "    \"\"\"\n",
    "    Generate all multi-indices with total degree up to 'degree' for d-dimensional points.\n",
    "    \n",
    "    Parameters:\n",
    "        d (int): The dimension of the points.\n",
    "        degree (int): The maximum degree of the monomials.\n",
    "    \n",
    "    Returns:\n",
    "        ndarray: The multi-indices of shape (num_poly, d).\n",
    "    \"\"\"\n",
    "    num_poly = math.comb(degree + d, d)\n",
    "    exponents = torch.zeros(num_poly, d, dtype=int)\n",
    "    i = 0\n",
    "    for total_degree in range(degree + 1):\n",
    "        for exps in combinations_with_replacement(range(d), total_degree):\n",
    "            for var in exps:\n",
    "                exponents[i, var] += 1\n",
    "            i += 1\n",
    "            \n",
    "    return exponents\n",
    "\n",
    "def generate_monomials_sequences_batch(X, exponents):\n",
    "    \"\"\"\n",
    "    Generate monomials given a point cloud and multi-indices.\n",
    "\n",
    "    Parameters:\n",
    "        X (ndarray): An array of shape (B, N, d) representing the point cloud.\n",
    "        exponents (ndarray): The multi-indices of shape (M, d).\n",
    "\n",
    "    Returns:\n",
    "        ndarray: Monomial sequences of shape (B, M).\n",
    "    \"\"\"\n",
    "    B, N, d = X.shape\n",
    "    device = X.device\n",
    "    exponents = exponents.to(device)\n",
    "    M = len(exponents)\n",
    "    # print(f'Number of monomials: {M}') # Number of polynomials: n1 + n2 + ... + n_d = degree; degree + d choose d; d number of dividers for an array in space R^d.\n",
    "    monomials = torch.ones(B, N, M, device=device)\n",
    "    for i, exp in enumerate(exponents):\n",
    "        monomials[:, :, i] = torch.prod(X ** exp, axis=2) # x1^exp1 * x2^exp2 * ... * xd^expd. e.g. x1^2 * x2^3 * x3^1 \\in R^3\n",
    "    return monomials.sum(dim=1) / N # (B, N, M) -> (B, M)\n",
    "\n",
    "def generate_chebyshev_polynomials_sequence_batch_old(X, exponents):\n",
    "    \"\"\"\n",
    "    Generate Chebyshev polynomials given a point cloud and multi-indices.\n",
    "\n",
    "    Parameters:\n",
    "        X (ndarray): An array of shape (B, N, d) representing the d-dimensional point cloud.\n",
    "        exponents (ndarray): The multi-indices of shape (M, d).\n",
    "\n",
    "    Returns:\n",
    "        ndarray: Chebyshev polynomial sequences of shape (B, M).\n",
    "    \"\"\"\n",
    "    B, N, d = X.shape\n",
    "    device = X.device\n",
    "    exponents = exponents.to(device)\n",
    "    # print(f'Number of Chebyshev polynomials: {M}') # Number of polynomials: n1 + n2 + ... + n_d = degree; degree + d choose d; d number of dividers for an array in space R^d.\n",
    "    cheby_polynomials = torch.ones(B, N, M, device=device)\n",
    "    for i, exp in enumerate(exponents):\n",
    "        cheby_polynomials[:, :, i] = torch.prod(torch.cos(exp * torch.acos(X)), axis=2)\n",
    "    \n",
    "    return cheby_polynomials.sum(dim=1) / N # (B, N, M) -> (B, M)\n",
    "\n",
    "def generate_chebyshev_polynomials_sequence_batch(X, exponents):\n",
    "    \"\"\"\n",
    "    Generate Chebyshev polynomials given a point cloud and multi-indices.\n",
    "\n",
    "    Parameters:\n",
    "        X (ndarray): An array of shape (B, N, d) representing the d-dimensional point cloud.\n",
    "        exponents (ndarray): The multi-indices of shape (M, d).\n",
    "\n",
    "    Returns:\n",
    "        ndarray: Chebyshev polynomial sequences of shape (B, M).\n",
    "    \"\"\"\n",
    "    B, N, d = X.shape\n",
    "    device = X.device\n",
    "    exponents = exponents.to(device)\n",
    "    cheby_polynomials = torch.cos(exponents.unsqueeze(0).unsqueeze(0) * torch.acos(X).unsqueeze(2)) # (B, N, M)\n",
    "    cheby_polynomials = cheby_polynomials.prod(dim=-1) # (B, N)\n",
    "    \n",
    "    return cheby_polynomials.sum(dim=1) / N # (B, N, M) -> (B, M)\n",
    "\n",
    "def poly_seq_batch(X, exponents, poly_type='monomial'):\n",
    "    if poly_type == 'monomial':\n",
    "        return generate_monomials_sequences_batch(X, exponents)\n",
    "    elif poly_type == 'chebyshev':\n",
    "        return generate_chebyshev_polynomials_sequence_batch(X, exponents)\n",
    "    else:\n",
    "        raise ValueError('Unknown polynomial type')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exponents = generate_exponents(d, degree)\n",
    "# print('exponents:', exponents.shape, exponents[:10])\n",
    "\n",
    "# X = torch.rand(2, 100, 3)\n",
    "# polys = generate_chebyshev_polynomials_sequence_batch(X, exponents)\n",
    "# print('polys:', polys.shape, polys[0, :10])\n",
    "\n",
    "# polys = generate_chebyshev_polynomials_sequence_batch_old(X, exponents)\n",
    "# print('polys:', polys.shape, polys[0, :10])\n",
    "\n",
    "# # time the above functions\n",
    "# import time\n",
    "\n",
    "# X = torch.rand(2, 100, 3)\n",
    "# start = time.time()\n",
    "# polys = generate_chebyshev_polynomials_sequence_batch(X, exponents)\n",
    "# print('Time:', time.time() - start)\n",
    "\n",
    "# start = time.time()\n",
    "# polys = generate_chebyshev_polynomials_sequence_batch_old(X, exponents)\n",
    "# print('Time:', time.time() - start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use ModelNet40 as our dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_points = 2048\n",
    "batch_size = 32\n",
    "\n",
    "train_loader = DataLoader(ModelNet40(partition='train', \n",
    "                                        num_points=num_points,\n",
    "                                        aug=True), \n",
    "                            num_workers=8,\n",
    "                            batch_size=batch_size, \n",
    "                            shuffle=True, \n",
    "                            drop_last=True)\n",
    "test_loader = DataLoader(ModelNet40(partition='test', \n",
    "                                        num_points=num_points,\n",
    "                                        aug=False), \n",
    "                            num_workers=8,\n",
    "                            batch_size=batch_size // 2, \n",
    "                            shuffle=False, \n",
    "                            drop_last=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A simple Linear classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 40])\n"
     ]
    }
   ],
   "source": [
    "class MLPClaasifier(nn.Module):\n",
    "    def __init__(self, dim_in, layer_dims, dim_out, dropout=0.5):\n",
    "        super(MLPClaasifier, self).__init__()\n",
    "        self.convs = nn.ModuleList()\n",
    "        self.convs.append(nn.Sequential(\n",
    "            nn.Linear(dim_in, layer_dims[0]),\n",
    "            nn.BatchNorm1d(layer_dims[0]),\n",
    "            nn.ReLU(),\n",
    "        ))\n",
    "        for i in range(1, len(layer_dims)):\n",
    "            self.convs.append(nn.Sequential(\n",
    "                nn.Linear(layer_dims[i-1], layer_dims[i]),\n",
    "                nn.BatchNorm1d(layer_dims[i]),\n",
    "                nn.Dropout(dropout),\n",
    "                nn.ReLU(),\n",
    "            ))\n",
    "        self.convs.append(nn.Linear(layer_dims[-1], dim_out))\n",
    "\n",
    "    def forward(self, x):\n",
    "        for i, conv in enumerate(self.convs[:-1]):\n",
    "            x = conv(x)\n",
    "        x = self.convs[-1](x)\n",
    "        return x\n",
    "    \n",
    "x = torch.randn(32, 100) # 32 samples, 100 features\n",
    "model = MLPClaasifier(100, [128, 64], 40)\n",
    "y = model(x)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 40])\n"
     ]
    }
   ],
   "source": [
    "class MomentNet(nn.Module):\n",
    "    def __init__(self, dim_in, layer_dims, dim_out, degree, poly_type='chebyshev'):\n",
    "        super(MomentNet, self).__init__()\n",
    "        self.poly_type = poly_type\n",
    "        self.exponts = generate_exponents(dim_in, degree)\n",
    "        self.num_poly = len(self.exponts)\n",
    "        self.mlp = MLPClaasifier(self.num_poly, layer_dims, dim_out)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = poly_seq_batch(x, self.exponts, self.poly_type)\n",
    "        x = self.mlp(x)\n",
    "        return x\n",
    "    \n",
    "x = torch.randn(32, 2048, 3) # 32 samples, 2048 points, 3 features\n",
    "model = MomentNet(3, [128, 64], 40, 2, 'monomial')\n",
    "y = model(x)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(net, trainloader, optimizer, criterion, epoch, num_epochs, device):\n",
    "    net.train()\n",
    "    train_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    train_pred = []\n",
    "    train_true = []\n",
    "    time_cost = datetime.datetime.now()\n",
    "    pbar = tqdm(enumerate(trainloader), total=len(trainloader))\n",
    "    for batch_idx, (data, label) in pbar:\n",
    "        data, label = data.to(device), label.to(device).squeeze()\n",
    "        optimizer.zero_grad()\n",
    "        logits = net(data)\n",
    "        loss = criterion(logits, label)\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(net.parameters(), 1)\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()\n",
    "        preds = logits.max(dim=1)[1]\n",
    "\n",
    "        train_true.append(label.cpu().numpy())\n",
    "        train_pred.append(preds.detach().cpu().numpy())\n",
    "\n",
    "        total += label.size(0)\n",
    "        correct += preds.eq(label).sum().item()\n",
    "\n",
    "        pbar.set_description(f'({epoch:3d}/{num_epochs:3d}) Loss: {train_loss / (batch_idx + 1):.3f} | Acc: {100. * correct / total:.3f}% ({correct}/{total})')\n",
    "        # progress_bar(batch_idx, len(trainloader), 'Loss: %.3f | Acc: %.3f%% (%d/%d)'\n",
    "        #              % (train_loss / (batch_idx + 1), 100. * correct / total, correct, total))\n",
    "\n",
    "    time_cost = int((datetime.datetime.now() - time_cost).total_seconds())\n",
    "    train_true = np.concatenate(train_true)\n",
    "    train_pred = np.concatenate(train_pred)\n",
    "    return {\n",
    "        \"loss\": float(\"%.3f\" % (train_loss / (batch_idx + 1))),\n",
    "        \"acc\": float(\"%.3f\" % (100. * metrics.accuracy_score(train_true, train_pred))),\n",
    "        \"acc_avg\": float(\"%.3f\" % (100. * metrics.balanced_accuracy_score(train_true, train_pred))),\n",
    "        \"time\": time_cost\n",
    "    }\n",
    "\n",
    "\n",
    "def validate(net, testloader, criterion, epoch, num_epochs, device):\n",
    "    net.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    test_true = []\n",
    "    test_pred = []\n",
    "    time_cost = datetime.datetime.now()\n",
    "    with torch.no_grad():\n",
    "        pbar = tqdm(enumerate(testloader), total=len(testloader))\n",
    "        for batch_idx, (data, label) in pbar:\n",
    "            data, label = data.to(device), label.to(device).squeeze()\n",
    "            logits = net(data)\n",
    "            loss = criterion(logits, label)\n",
    "            test_loss += loss.item()\n",
    "            preds = logits.max(dim=1)[1]\n",
    "            test_true.append(label.cpu().numpy())\n",
    "            test_pred.append(preds.detach().cpu().numpy())\n",
    "            total += label.size(0)\n",
    "            correct += preds.eq(label).sum().item()\n",
    "            pbar.set_description(f'({epoch:3d}/{num_epochs:3d}) Loss: {test_loss / (batch_idx + 1):.3f} | Acc: {100. * correct / total:.3f}% ({correct}/{total})')\n",
    "            # progress_bar(batch_idx, len(testloader), 'Loss: %.3f | Acc: %.3f%% (%d/%d)'\n",
    "            #              % (test_loss / (batch_idx + 1), 100. * correct / total, correct, total))\n",
    "\n",
    "    time_cost = int((datetime.datetime.now() - time_cost).total_seconds())\n",
    "    test_true = np.concatenate(test_true)\n",
    "    test_pred = np.concatenate(test_pred)\n",
    "    return {\n",
    "        \"loss\": float(\"%.3f\" % (test_loss / (batch_idx + 1))),\n",
    "        \"acc\": float(\"%.3f\" % (100. * metrics.accuracy_score(test_true, test_pred))),\n",
    "        \"acc_avg\": float(\"%.3f\" % (100. * metrics.balanced_accuracy_score(test_true, test_pred))),\n",
    "        \"time\": time_cost\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "680\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(  0/100) Loss: 1.638 | Acc: 56.504% (5551/9824): 100%|██████████| 307/307 [00:02<00:00, 117.81it/s]\n",
      "(  0/100) Loss: 1.097 | Acc: 67.301% (1661/2468): 100%|██████████| 155/155 [00:00<00:00, 336.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss:1.638 acc_avg:39.683% acc:56.504% time:2s\n",
      "Testing loss:1.097 acc_avg:54.443% acc:67.301% time:0s [best test acc: 67.301%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(  1/100) Loss: 1.143 | Acc: 67.498% (6631/9824): 100%|██████████| 307/307 [00:02<00:00, 151.58it/s]\n",
      "(  1/100) Loss: 0.945 | Acc: 72.285% (1784/2468): 100%|██████████| 155/155 [00:00<00:00, 331.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss:1.143 acc_avg:54.314% acc:67.498% time:2s\n",
      "Testing loss:0.945 acc_avg:64.248% acc:72.285% time:0s [best test acc: 72.285%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(  2/100) Loss: 1.008 | Acc: 71.427% (7017/9824): 100%|██████████| 307/307 [00:02<00:00, 150.96it/s]\n",
      "(  2/100) Loss: 0.762 | Acc: 76.945% (1899/2468): 100%|██████████| 155/155 [00:00<00:00, 323.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss:1.008 acc_avg:59.83% acc:71.427% time:2s\n",
      "Testing loss:0.762 acc_avg:66.195% acc:76.945% time:0s [best test acc: 76.945%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(  3/100) Loss: 0.926 | Acc: 72.883% (7160/9824): 100%|██████████| 307/307 [00:02<00:00, 148.30it/s]\n",
      "(  3/100) Loss: 0.772 | Acc: 77.188% (1905/2468): 100%|██████████| 155/155 [00:00<00:00, 302.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss:0.926 acc_avg:61.479% acc:72.883% time:2s\n",
      "Testing loss:0.772 acc_avg:67.783% acc:77.188% time:0s [best test acc: 77.188%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(  4/100) Loss: 1.307 | Acc: 64.062% (41/64):   1%|          | 2/307 [00:00<00:12, 24.11it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 26\u001b[0m\n\u001b[1;32m     23\u001b[0m criterion \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mCrossEntropyLoss()\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(start_epoch, num_epochs):\n\u001b[0;32m---> 26\u001b[0m     train_out \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnet\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# {\"loss\", \"acc\", \"acc_avg\", \"time\"}\u001b[39;00m\n\u001b[1;32m     27\u001b[0m     test_out \u001b[38;5;241m=\u001b[39m validate(net, test_loader, criterion, epoch, num_epochs, device)\n\u001b[1;32m     28\u001b[0m     scheduler\u001b[38;5;241m.\u001b[39mstep()\n",
      "Cell \u001b[0;32mIn[8], line 10\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(net, trainloader, optimizer, criterion, epoch, num_epochs, device)\u001b[0m\n\u001b[1;32m      8\u001b[0m time_cost \u001b[38;5;241m=\u001b[39m datetime\u001b[38;5;241m.\u001b[39mdatetime\u001b[38;5;241m.\u001b[39mnow()\n\u001b[1;32m      9\u001b[0m pbar \u001b[38;5;241m=\u001b[39m tqdm(\u001b[38;5;28menumerate\u001b[39m(trainloader), total\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlen\u001b[39m(trainloader))\n\u001b[0;32m---> 10\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch_idx, (data, label) \u001b[38;5;129;01min\u001b[39;00m pbar:\n\u001b[1;32m     11\u001b[0m     data, label \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mto(device), label\u001b[38;5;241m.\u001b[39mto(device)\u001b[38;5;241m.\u001b[39msqueeze()\n\u001b[1;32m     12\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n",
      "File \u001b[0;32m~/miniconda3/envs/pytorch3d/lib/python3.9/site-packages/tqdm/std.py:1182\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1179\u001b[0m time \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_time\n\u001b[1;32m   1181\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1182\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m obj \u001b[38;5;129;01min\u001b[39;00m iterable:\n\u001b[1;32m   1183\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m obj\n\u001b[1;32m   1184\u001b[0m         \u001b[38;5;66;03m# Update and possibly print the progressbar.\u001b[39;00m\n\u001b[1;32m   1185\u001b[0m         \u001b[38;5;66;03m# Note: does not call self.update(1) for speed optimisation.\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/pytorch3d/lib/python3.9/site-packages/torch/utils/data/dataloader.py:628\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    625\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    626\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    627\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 628\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    629\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    630\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    631\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    632\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/miniconda3/envs/pytorch3d/lib/python3.9/site-packages/torch/utils/data/dataloader.py:1316\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1313\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_data(data)\n\u001b[1;32m   1315\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_shutdown \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tasks_outstanding \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m-> 1316\u001b[0m idx, data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1317\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tasks_outstanding \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1318\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable:\n\u001b[1;32m   1319\u001b[0m     \u001b[38;5;66;03m# Check for _IterableDatasetStopIteration\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/pytorch3d/lib/python3.9/site-packages/torch/utils/data/dataloader.py:1282\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1278\u001b[0m     \u001b[38;5;66;03m# In this case, `self._data_queue` is a `queue.Queue`,. But we don't\u001b[39;00m\n\u001b[1;32m   1279\u001b[0m     \u001b[38;5;66;03m# need to call `.task_done()` because we don't use `.join()`.\u001b[39;00m\n\u001b[1;32m   1280\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1281\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m-> 1282\u001b[0m         success, data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_try_get_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1283\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m success:\n\u001b[1;32m   1284\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "File \u001b[0;32m~/miniconda3/envs/pytorch3d/lib/python3.9/site-packages/torch/utils/data/dataloader.py:1120\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1107\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_try_get_data\u001b[39m(\u001b[38;5;28mself\u001b[39m, timeout\u001b[38;5;241m=\u001b[39m_utils\u001b[38;5;241m.\u001b[39mMP_STATUS_CHECK_INTERVAL):\n\u001b[1;32m   1108\u001b[0m     \u001b[38;5;66;03m# Tries to fetch data from `self._data_queue` once for a given timeout.\u001b[39;00m\n\u001b[1;32m   1109\u001b[0m     \u001b[38;5;66;03m# This can also be used as inner loop of fetching without timeout, with\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1117\u001b[0m     \u001b[38;5;66;03m# Returns a 2-tuple:\u001b[39;00m\n\u001b[1;32m   1118\u001b[0m     \u001b[38;5;66;03m#   (bool: whether successfully get data, any: data if successful else None)\u001b[39;00m\n\u001b[1;32m   1119\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1120\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_data_queue\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1121\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[38;5;28;01mTrue\u001b[39;00m, data)\n\u001b[1;32m   1122\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   1123\u001b[0m         \u001b[38;5;66;03m# At timeout and error, we manually check whether any worker has\u001b[39;00m\n\u001b[1;32m   1124\u001b[0m         \u001b[38;5;66;03m# failed. Note that this is the only mechanism for Windows to detect\u001b[39;00m\n\u001b[1;32m   1125\u001b[0m         \u001b[38;5;66;03m# worker failures.\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/pytorch3d/lib/python3.9/multiprocessing/queues.py:113\u001b[0m, in \u001b[0;36mQueue.get\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m block:\n\u001b[1;32m    112\u001b[0m     timeout \u001b[38;5;241m=\u001b[39m deadline \u001b[38;5;241m-\u001b[39m time\u001b[38;5;241m.\u001b[39mmonotonic()\n\u001b[0;32m--> 113\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_poll\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m    114\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m Empty\n\u001b[1;32m    115\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_poll():\n",
      "File \u001b[0;32m~/miniconda3/envs/pytorch3d/lib/python3.9/multiprocessing/connection.py:257\u001b[0m, in \u001b[0;36m_ConnectionBase.poll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    255\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_closed()\n\u001b[1;32m    256\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_readable()\n\u001b[0;32m--> 257\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_poll\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/pytorch3d/lib/python3.9/multiprocessing/connection.py:424\u001b[0m, in \u001b[0;36mConnection._poll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    423\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_poll\u001b[39m(\u001b[38;5;28mself\u001b[39m, timeout):\n\u001b[0;32m--> 424\u001b[0m     r \u001b[38;5;241m=\u001b[39m \u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    425\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mbool\u001b[39m(r)\n",
      "File \u001b[0;32m~/miniconda3/envs/pytorch3d/lib/python3.9/multiprocessing/connection.py:931\u001b[0m, in \u001b[0;36mwait\u001b[0;34m(object_list, timeout)\u001b[0m\n\u001b[1;32m    928\u001b[0m     deadline \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mmonotonic() \u001b[38;5;241m+\u001b[39m timeout\n\u001b[1;32m    930\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 931\u001b[0m     ready \u001b[38;5;241m=\u001b[39m \u001b[43mselector\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mselect\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    932\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ready:\n\u001b[1;32m    933\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [key\u001b[38;5;241m.\u001b[39mfileobj \u001b[38;5;28;01mfor\u001b[39;00m (key, events) \u001b[38;5;129;01min\u001b[39;00m ready]\n",
      "File \u001b[0;32m~/miniconda3/envs/pytorch3d/lib/python3.9/selectors.py:416\u001b[0m, in \u001b[0;36m_PollLikeSelector.select\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    414\u001b[0m ready \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    415\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 416\u001b[0m     fd_event_list \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_selector\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpoll\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    417\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mInterruptedError\u001b[39;00m:\n\u001b[1;32m    418\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ready\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Training (Taken from PointMLP-PyTorch)\n",
    "device = torch.device('cuda:1' if torch.cuda.is_available() else 'cpu')\n",
    "num_epochs = 100 # Number of epochs\n",
    "eval_every = 10 # Evaluate every 'eval_every' epochs\n",
    "max_lr = 0.1 # Maximum learning rate\n",
    "min_lr = 0.005 # Minimum learning rate\n",
    "\n",
    "best_test_acc = 0.  # best test accuracy\n",
    "best_train_acc = 0.\n",
    "best_test_acc_avg = 0.\n",
    "best_train_acc_avg = 0.\n",
    "best_test_loss = float(\"inf\")\n",
    "best_train_loss = float(\"inf\")\n",
    "start_epoch = 0  # start from epoch 0 or last checkpoint epoch\n",
    "\n",
    "# Model\n",
    "net = MomentNet(3, [256, 128], 40, degree = 14, poly_type = 'chebyshev').to(device)\n",
    "print(net.num_poly)\n",
    "\n",
    "# Optimizer\n",
    "optimizer = torch.optim.SGD(net.parameters(), lr=max_lr, momentum=0.9, weight_decay=0)\n",
    "scheduler = CosineAnnealingLR(optimizer, num_epochs, eta_min=min_lr, last_epoch=start_epoch - 1)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "for epoch in range(start_epoch, num_epochs):\n",
    "    train_out = train(net, train_loader, optimizer, criterion, epoch, num_epochs, device)  # {\"loss\", \"acc\", \"acc_avg\", \"time\"}\n",
    "    test_out = validate(net, test_loader, criterion, epoch, num_epochs, device)\n",
    "    scheduler.step()\n",
    "    if test_out[\"acc\"] > best_test_acc:\n",
    "        best_test_acc = test_out[\"acc\"]\n",
    "        is_best = True\n",
    "    else:\n",
    "        is_best = False\n",
    "\n",
    "    best_test_acc = test_out[\"acc\"] if (test_out[\"acc\"] > best_test_acc) else best_test_acc\n",
    "    best_train_acc = train_out[\"acc\"] if (train_out[\"acc\"] > best_train_acc) else best_train_acc\n",
    "    best_test_acc_avg = test_out[\"acc_avg\"] if (test_out[\"acc_avg\"] > best_test_acc_avg) else best_test_acc_avg\n",
    "    best_train_acc_avg = train_out[\"acc_avg\"] if (train_out[\"acc_avg\"] > best_train_acc_avg) else best_train_acc_avg\n",
    "    best_test_loss = test_out[\"loss\"] if (test_out[\"loss\"] < best_test_loss) else best_test_loss\n",
    "    best_train_loss = train_out[\"loss\"] if (train_out[\"loss\"] < best_train_loss) else best_train_loss\n",
    "    \n",
    "    print(\n",
    "        f\"Training loss:{train_out['loss']} acc_avg:{train_out['acc_avg']}% acc:{train_out['acc']}% time:{train_out['time']}s\")\n",
    "    print(\n",
    "        f\"Testing loss:{test_out['loss']} acc_avg:{test_out['acc_avg']}% \"\n",
    "        f\"acc:{test_out['acc']}% time:{test_out['time']}s [best test acc: {best_test_acc}%]\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch3d",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
